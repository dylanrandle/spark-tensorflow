{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from IPython.display import YouTubeVideo\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import multiprocessing as mp # if we want to parallelize i/o\n",
    "\n",
    "# keras imports\n",
    "from keras.layers import Dense, Input, LSTM, Dropout, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "import operator\n",
    "import time \n",
    "import gc\n",
    "import os\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.types import *\n",
    "import pyspark\n",
    "import numpy as np\n",
    "from elephas.spark_model import SparkModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName('Youtube-8M') \\\n",
    "                  .set(\"spark.jars\",\n",
    "                       \"ecosystem/spark/spark-tensorflow-connector/target/spark-tensorflow-connector_2.11-1.10.0.jar\")\n",
    "sc = SparkContext(conf = conf)\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train0093.tfrecord-converted.tfrecord  train0208.tfrecord-converted.tfrecord\r\n",
      "train0111.tfrecord-converted.tfrecord\r\n"
     ]
    }
   ],
   "source": [
    "!ls mys3bucket/converted_records_for_spark/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"tfrecords\").option(\"recordType\", \"SequenceExample\").load('mys3bucket/converted_records_for_spark/*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3044"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          mean_audio|              labels|            mean_rgb|           frame_rgb|         frame_audio|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|[-1.185913, -0.84...|[0.0, 0.0, 1.0, 0...|[0.53471446, 1.00...|[WrappedArray(238...|[WrappedArray(86....|\n",
      "|[0.9230174, -0.34...|[0.0, 0.0, 0.0, 0...|[-0.10382305, -1....|[WrappedArray(51....|[WrappedArray(192...|\n",
      "|[-0.32460678, -0....|[0.0, 0.0, 0.0, 0...|[-0.5026991, -1.6...|[WrappedArray(0.0...|[WrappedArray(173...|\n",
      "|[0.9312072, -0.73...|[0.0, 0.0, 0.0, 0...|[-0.6032936, -0.4...|[WrappedArray(0.0...|[WrappedArray(163...|\n",
      "|[0.11735498, 1.13...|[0.0, 0.0, 0.0, 0...|[0.61926347, 0.20...|[WrappedArray(121...|[WrappedArray(121...|\n",
      "|[-0.83108944, -1....|[0.0, 0.0, 0.0, 0...|[0.48174715, 0.67...|[WrappedArray(73....|[WrappedArray(75....|\n",
      "|[-0.6435339, -0.6...|[1.0, 1.0, 0.0, 0...|[0.024073938, -0....|[WrappedArray(0.0...|[WrappedArray(177...|\n",
      "|[-1.6815804, 1.89...|[1.0, 0.0, 0.0, 0...|[0.13661005, -1.3...|[WrappedArray(146...|[WrappedArray(50....|\n",
      "|[1.294819, 1.5030...|[0.0, 0.0, 0.0, 1...|[0.4091197, -0.62...|[WrappedArray(153...|[WrappedArray(190...|\n",
      "|[1.175444, 1.8621...|[0.0, 0.0, 0.0, 1...|[-0.8292868, 0.38...|[WrappedArray(25....|[WrappedArray(194...|\n",
      "|[0.039699353, 0.4...|[0.0, 0.0, 0.0, 0...|[0.43012044, -1.5...|[WrappedArray(110...|[WrappedArray(173...|\n",
      "|[-0.3033509, -0.6...|[0.0, 0.0, 0.0, 0...|[0.28378636, 0.80...|[WrappedArray(0.0...|[WrappedArray(129...|\n",
      "|[-1.2610502, 1.55...|[1.0, 0.0, 0.0, 0...|[-0.13540319, 0.1...|[WrappedArray(120...|[WrappedArray(91....|\n",
      "|[-0.66810906, -0....|[0.0, 0.0, 0.0, 0...|[0.83819157, 1.09...|[WrappedArray(0.0...|[WrappedArray(136...|\n",
      "|[0.8888252, -0.41...|[1.0, 1.0, 0.0, 0...|[1.269664, 0.0225...|[WrappedArray(165...|[WrappedArray(178...|\n",
      "|[-1.3135805, 0.76...|[0.0, 0.0, 0.0, 0...|[0.21302176, 0.91...|[WrappedArray(172...|[WrappedArray(14....|\n",
      "|[-0.71007967, -0....|[0.0, 0.0, 0.0, 0...|[-0.28900123, 0.1...|[WrappedArray(0.0...|[WrappedArray(173...|\n",
      "|[-1.155377, -0.57...|[0.0, 0.0, 1.0, 0...|[0.3896687, -0.54...|[WrappedArray(0.0...|[WrappedArray(173...|\n",
      "|[-0.16980188, -0....|[1.0, 0.0, 0.0, 0...|[-0.09913194, 0.4...|[WrappedArray(108...|[WrappedArray(164...|\n",
      "|[0.45434844, 0.46...|[1.0, 1.0, 0.0, 0...|[0.12007394, -0.5...|[WrappedArray(0.0...|[WrappedArray(140...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
