{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-LSTM video classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from IPython.display import YouTubeVideo\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import multiprocessing as mp # if we want to parallelize i/o\n",
    "\n",
    "# keras imports\n",
    "from keras.layers import Dense, Input, LSTM, Dropout, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "import operator\n",
    "import time \n",
    "import gc\n",
    "import os\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.types import *\n",
    "import pyspark\n",
    "import numpy as np\n",
    "from elephas.spark_model import SparkModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "#SPECIFY PARAMS FIRST\n",
    "###########\n",
    "\n",
    "# 10 class problem for now?\n",
    "label_feature_size = 1000\n",
    "\n",
    "# how many frames we will use from each video?\n",
    "max_frame_rgb_sequence_length = 100\n",
    "frame_rgb_embedding_size = 1024\n",
    "\n",
    "# how many audio sequences we will use from each video?\n",
    "max_frame_audio_sequence_length = 100\n",
    "frame_audio_embedding_size = 128\n",
    "\n",
    "number_dense_units = 1000\n",
    "number_lstm_units = 100\n",
    "rate_drop_lstm = 0.2\n",
    "rate_drop_dense = 0.2\n",
    "activation_function='relu'\n",
    "validation_split_ratio = 0 # to use all\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"Create and store best model at `checkpoint` path ustilising bi-lstm layer for frame level data of videos\"\"\"\n",
    "    \n",
    "    # Creating 2 bi-lstm layer, one for rgb and other for audio level data\n",
    "    lstm_layer_1 = Bidirectional(LSTM(number_lstm_units, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
    "    lstm_layer_2 = Bidirectional(LSTM(number_lstm_units, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
    "    \n",
    "    # creating input layer for frame-level data\n",
    "    frame_rgb_sequence_input = Input(shape=(max_frame_rgb_sequence_length, frame_rgb_embedding_size), dtype='float32')\n",
    "    frame_audio_sequence_input = Input(shape=(max_frame_audio_sequence_length, frame_audio_embedding_size), dtype='float32')\n",
    "    frame_x1 = lstm_layer_1(frame_rgb_sequence_input)\n",
    "    frame_x2 = lstm_layer_2(frame_audio_sequence_input)\n",
    "    \n",
    "    #creating input layer for video-level data \n",
    "    vid_shape=(1024,)\n",
    "    video_rgb_input = Input(shape=vid_shape)\n",
    "    video_rgb_dense = Dense(int(number_dense_units/2), activation=activation_function, input_shape=vid_shape)(video_rgb_input)\n",
    "    \n",
    "    aud_shape=(128,)\n",
    "    video_audio_input = Input(shape=aud_shape)\n",
    "    video_audio_dense = Dense(int(number_dense_units/2), activation=activation_function,input_shape = aud_shape)(video_audio_input)\n",
    "    \n",
    "    # merging frame-level bi-lstm output and later passed to dense layer by applying batch-normalisation and dropout\n",
    "    merged_frame = concatenate([frame_x1, frame_x2])\n",
    "    merged_frame = BatchNormalization()(merged_frame)\n",
    "    merged_frame = Dropout(rate_drop_dense)(merged_frame)\n",
    "    merged_frame_dense = Dense(int(number_dense_units/2), activation=activation_function)(merged_frame)\n",
    "    \n",
    "    # merging video-level dense layer output\n",
    "    merged_video = concatenate([video_rgb_dense, video_audio_dense])\n",
    "    merged_video = BatchNormalization()(video_rgb_dense)\n",
    "    merged_video = Dropout(rate_drop_dense)(merged_video)\n",
    "    merged_video_dense = Dense(int(number_dense_units/2), activation=activation_function)(merged_video)\n",
    "\n",
    "    \n",
    "    # merging frame-level and video-level dense layer output\n",
    "    merged = concatenate([merged_frame_dense, merged_video_dense])\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dropout(rate_drop_dense)(merged)\n",
    "     \n",
    "    merged = Dense(number_dense_units, activation=activation_function)(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dropout(rate_drop_dense)(merged)\n",
    "    preds = Dense(label_feature_size, activation='sigmoid')(merged)\n",
    "    \n",
    "    model = Model(inputs=[frame_rgb_sequence_input, frame_audio_sequence_input, video_rgb_input, video_audio_input], outputs=preds)\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_files(video_files_path):    \n",
    "    '''\n",
    "    Extraction of Youtube tfrecords video file features.\n",
    "    \n",
    "    Args: path to video files (note: developed with assumption of storing on s3 bucket and assessing with glob)\n",
    "    \n",
    "    Assumes each video in the tfrecord has following features:\n",
    "    'id' : bytes_list\n",
    "    'labels' : int64_list\n",
    "    'mean_rgb': float_list\n",
    "    'mean_audio': float_list\n",
    "    \n",
    "    returns:\n",
    "    numpy arrays of video ids, video multi-labels, mean rgb and mean audio\n",
    "    '''\n",
    "    \n",
    "    vid_ids = []\n",
    "    labels = []\n",
    "    mean_rgb = []\n",
    "    mean_audio = []\n",
    "\n",
    "    for file in tqdm(glob(video_files_path)):\n",
    "        for example in tf.python_io.tf_record_iterator(file):\n",
    "            tf_example = tf.train.Example.FromString(example)\n",
    "\n",
    "            vid_ids.append(tf_example.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8'))\n",
    "            labels.append(tf_example.features.feature['labels'].int64_list.value)\n",
    "            mean_rgb.append(tf_example.features.feature['mean_rgb'].float_list.value)\n",
    "            mean_audio.append(tf_example.features.feature['mean_audio'].float_list.value)\n",
    "            \n",
    "    assert len(vid_ids) == len(labels),\"The number of IDs does not match the number of labeled videos.\"\n",
    "    return vid_ids, labels, mean_rgb, mean_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frame_level_features_per_tf_record(frame_file_path,maximum_iter = False,stop_at_iter = 10):\n",
    "    '''\n",
    "    Extraction of Youtube tfrecords frame file features.\n",
    "    \n",
    "    Args: \n",
    "    path to each tf_record (note: developed with assumption of storing on s3 bucket and assessing with glob)\n",
    "    \n",
    "    maximum_iter - flag- if True, will limit number of videos extracted from each TF record\n",
    "    stop_at_iter - number of videos to extract\n",
    "    num_tf_records - number of records to extract - WARNING!!! this is VERY slow, if bigger than 1\n",
    "    \n",
    "    Assumes each video in the tfrecord has following features:\n",
    "    'id' : bytes_list\n",
    "    'labels' : int64_list\n",
    "    'audio': float arr, each frame 128\n",
    "    'rgb', float arr, each frame 1024\n",
    "    \n",
    "    returns:\n",
    "    numpy arrays of frame ids, frame multi-labels, frame audio, frame rgb\n",
    "    '''\n",
    "    frame_ids = []\n",
    "    frame_labels = []\n",
    "    feat_rgb = []\n",
    "    feat_audio = []\n",
    "    # ATTENTION: only use one TF record for debugging.\n",
    "    print(f'There is {sum(1 for _ in tf.python_io.tf_record_iterator(frame_file_path))} videos in this TF record.')\n",
    "    iter_ = 0\n",
    "    for example in tf.python_io.tf_record_iterator(frame_file_path):\n",
    "        if maximum_iter and iter_==stop_at_iter:\n",
    "            break\n",
    "        tf_example = tf.train.Example.FromString(example)\n",
    "\n",
    "        frame_ids.append(tf_example.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8'))\n",
    "        frame_labels.append(tf_example.features.feature['labels'].int64_list.value)\n",
    "\n",
    "        tf_seq_example = tf.train.SequenceExample.FromString(example)\n",
    "        n_frames = len(tf_seq_example.feature_lists.feature_list['audio'].feature)\n",
    "\n",
    "        rgb_frame = []\n",
    "        audio_frame = []\n",
    "\n",
    "        # iterate through frames\n",
    "        sys.stdout.flush()\n",
    "        for i in range(n_frames):\n",
    "            sess = tf.InteractiveSession()\n",
    "            sys.stdout.write('\\r'+'iterating video: ' + str(iter_)+ ' ,frames: ' + str(i)+'/'+str(n_frames))\n",
    "            sys.stdout.flush()\n",
    "            rgb_frame.append(tf.cast(tf.decode_raw(\n",
    "                    tf_seq_example.feature_lists.feature_list['rgb'].feature[i].bytes_list.value[0],tf.uint8)\n",
    "                           ,tf.float32).eval())\n",
    "            audio_frame.append(tf.cast(tf.decode_raw(\n",
    "                    tf_seq_example.feature_lists.feature_list['audio'].feature[i].bytes_list.value[0],tf.uint8)\n",
    "                           ,tf.float32).eval())\n",
    "\n",
    "            tf.reset_default_graph()\n",
    "            sess.close()\n",
    "        feat_rgb.append(rgb_frame)\n",
    "        feat_audio.append(audio_frame)\n",
    "        iter_+=1\n",
    "\n",
    "    return frame_ids, frame_labels, feat_rgb, feat_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_dev_dataset(video_rgb, video_audio, vid_ids, frame_rgb, frame_audio, frame_labels, frame_ids):\n",
    "    \"\"\"\n",
    "    Method to created training and validation data. \n",
    "    We need to make sure we only use video IDs for which we have frames.\n",
    "    This is handled below.\n",
    "    \n",
    "    \"\"\"\n",
    "    # we have to have the same video of for both video and frame-level features\n",
    "    video_rgb_matching = []\n",
    "    video_audio_matching = []\n",
    "    \n",
    "    for idx in frame_ids: # for each ID available on frame level, find matching video-level features\n",
    "        for i, idx_vid in enumerate(vid_ids): # scan through video-level ids\n",
    "            if idx == idx_vid: \n",
    "                video_rgb_matching.append(video_rgb[i])\n",
    "                video_audio_matching.append(video_audio[i])\n",
    "                \n",
    "                \n",
    "    shuffle_indices = np.random.permutation(np.arange(len(frame_labels)))\n",
    "        \n",
    "    video_rgb_shuffled = np.array(video_rgb_matching)[shuffle_indices]\n",
    "    video_audio_shuffled = np.array(video_audio_matching)[shuffle_indices]\n",
    "    frame_rgb_shuffled = np.array(frame_rgb)[shuffle_indices]\n",
    "    frame_audio_shuffled = np.array(frame_audio)[shuffle_indices]\n",
    "    labels_shuffled = np.array(frame_labels)[shuffle_indices]\n",
    "\n",
    "    dev_idx = max(1, int(len(labels_shuffled) * validation_split_ratio))\n",
    "    \n",
    "    # delete orig vars to clear some cache\n",
    "    del video_rgb\n",
    "    del video_audio\n",
    "    del frame_rgb\n",
    "    del frame_audio\n",
    "    gc.collect()\n",
    "    \n",
    "    train_video_rgb, val_video_rgb = video_rgb_shuffled[:-dev_idx], video_rgb_shuffled[-dev_idx:]\n",
    "    train_video_audio, val_video_audio = video_audio_shuffled[:-dev_idx], video_audio_shuffled[-dev_idx:]\n",
    "    \n",
    "    train_frame_rgb, val_frame_rgb = frame_rgb_shuffled[:-dev_idx], frame_rgb_shuffled[-dev_idx:]\n",
    "    train_frame_audio, val_frame_audio = frame_audio_shuffled[:-dev_idx], frame_audio_shuffled[-dev_idx:]\n",
    "    \n",
    "    train_labels, val_labels = labels_shuffled[:-dev_idx], labels_shuffled[-dev_idx:]\n",
    "    \n",
    "    del video_rgb_shuffled, video_audio_shuffled, frame_rgb_shuffled, frame_audio_shuffled, labels_shuffled\n",
    "    gc.collect()\n",
    "    \n",
    "    return (train_video_rgb, train_video_audio, train_frame_rgb, train_frame_audio, train_labels, val_video_rgb, val_video_audio, \n",
    "            val_frame_rgb, val_frame_audio, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform into final input in the model\n",
    "def one_hot_y(raw_labels,label_size=20):\n",
    "    '''\n",
    "    Helper function to transform labels into one-hot TOP 20\n",
    "    Uses np.unique(return_counts=True) as implicit sorter (first K labels are the most frequent)\n",
    "    '''\n",
    "    all_labels = []\n",
    "    for i in list(raw_labels):\n",
    "        for j in list(i):\n",
    "            all_labels.append(j)\n",
    "\n",
    "    results = np.unique(all_labels,return_counts=True)\n",
    "    labels_vocab,counts = results\n",
    "\n",
    "    labels = labels_vocab[:label_size-1] #last columns will be 1 if none of those labels found in a video\n",
    "    output = []\n",
    "    for set_of_labels in raw_labels:\n",
    "        \n",
    "        # preallocate numpy arr for each set of labels\n",
    "        sequence = np.zeros(label_size)\n",
    "        # loop through all the labels in one video and flip them to 1s\n",
    "        for this_label in set_of_labels:\n",
    "            designation = np.where(labels==this_label)\n",
    "            for des in designation:\n",
    "                sequence[des]=1\n",
    "        # done with one training points\n",
    "        if sequence.sum()==0:\n",
    "            sequence[-1]=1\n",
    "        output.append(sequence)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_for_lstm(video_rgb,video_audio, frame_rgb, frame_audio,\n",
    "                            labels,label_feature_size=10,max_frame_rgb_sequence_length = 10,\\\n",
    "                            max_frame_audio_sequence_length = 10):\n",
    "    frames = []\n",
    "    # need to transfrom to numpy (num_videos x max_frame_rgb_sequence_length x 1024)\n",
    "    #print(len(frame_rgb))\n",
    "    \n",
    "    for frame in frame_rgb: \n",
    "        # stack the frames in each video, only allowed number of first frams\n",
    "        #print(np.vstack(frame).shape)\n",
    "        frames.append(np.vstack(frame)[:max_frame_rgb_sequence_length,:])\n",
    "    #print(len(frames))\n",
    "\n",
    "    frames = np.reshape(np.array(frames),(len(frame_rgb),max_frame_rgb_sequence_length,1024))\n",
    "\n",
    "    #print(frames.shape)\n",
    "    \n",
    "    frames_audio = []\n",
    "    # need to transfrom to numpy (num_videos x max_frame_audio_sequence_length x 128)\n",
    "    for frame in frame_audio:\n",
    "        # stack the frames in each video, only allowed number of first frams\n",
    "        #print(np.vstack(frame).shape)\n",
    "        frames_audio.append(np.vstack(frame)[:max_frame_audio_sequence_length,:])\n",
    "\n",
    "    frames_audio = np.reshape(np.array(frames_audio),(len(frame_audio),max_frame_audio_sequence_length,128))\n",
    "    #print(frames_audio.shape)\n",
    "    \n",
    "    # deal with videos\n",
    "    \n",
    "    video_rgb = np.vstack(video_rgb)\n",
    "    video_audio = np.vstack(video_audio)\n",
    "    \n",
    "    \n",
    "    # labels - need to one-hot encode TOP - K label\n",
    "    labels = one_hot_y(labels,label_feature_size)\n",
    "    labels = np.vstack(labels)\n",
    "    return frames,frames_audio, video_rgb,video_audio, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run on SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pandas(frame_rgb, frame_audio, video_rgb, video_audio, labels):\n",
    "    '''\n",
    "    Spark unfortunately does not work with numpy arrays - so we need to convert to traditional python types.\n",
    "    '''\n",
    "    return pd.DataFrame.from_dict({'frame_rgb':[[[float(k) for k in j] for j in i] for i in frame_rgb],\\\n",
    "                             'frame_audio':[[[float(k) for k in j] for j in i] for i in frame_audio],\\\n",
    "                             'mean_rgb':[[float(j) for j in i] for i in list(video_rgb)],\\\n",
    "                            'mean_audio':[[float(j) for j in i] for i in list(video_audio)],\\\n",
    "                            'labels':[[float(j) for j in i] for i in list(labels)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName('Youtube-8M') \\\n",
    "                  .set(\"spark.jars\",\n",
    "                       \"ecosystem/spark/spark-tensorflow-connector/target/spark-tensorflow-connector_2.11-1.10.0.jar\")\n",
    "sc = SparkContext(conf = conf)\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-adf8daf949ef>:23: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:04<00:00,  9.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# We just load all of the video data in memory since it is fairly small and manageable.\n",
    "train_vid_ids, train_labels, train_mean_rgb, train_mean_audio \\\n",
    "    = extract_video_files(\"mys3bucket/yt8pm_100th_shard/v2/video/train*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the fun starts here, pull frame data per tf-record\n",
    "train_frame_shards = glob('mys3bucket/yt8pm_100th_shard/v2/frame/train*')\n",
    "val_frame_shards = glob('mys3bucket/yt8pm_100th_shard/v2/frame/validate*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frame_shards += val_frame_shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_frame_shards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1015 videos in this TF record.\n",
      "iterating video: 9 ,frames: 122/123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [00:34<00:34, 34.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1029 videos in this TF record.\n",
      "iterating video: 9 ,frames: 127/128"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:59<00:00, 31.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# iterate tf records one by one and append to spark dataframe\n",
    "\n",
    "FIRST_RECORD = True # flag whether to append to Spark SQL or create a new one\n",
    "NUM_RECORDS_TO_LOAD = 2\n",
    "\n",
    "for tf_record in tqdm(train_frame_shards[:NUM_RECORDS_TO_LOAD]):\n",
    "    # pull frames in memory\n",
    "    train_frame_ids, train_frame_labels,train_frame_rgb,train_frame_audio \\\n",
    "        = extract_frame_level_features_per_tf_record(tf_record,maximum_iter=True,\\\n",
    "                               stop_at_iter=10) # just pull 10 videos from each tf record for debugging\n",
    "    # first transformation\n",
    "    train_video_rgb, train_video_audio, train_frame_rgb, train_frame_audio, \\\n",
    "    train_labels, val_video_rgb, val_video_audio, val_frame_rgb, val_frame_audio, val_labels \\\n",
    "                = create_train_dev_dataset(train_mean_rgb, train_mean_audio, train_vid_ids, train_frame_rgb, \\\n",
    "                                            train_frame_audio, train_frame_labels, train_frame_ids )    \n",
    "    \n",
    "    # final transformation for LSTM\n",
    "    train_frame_rgb, train_frame_audio, train_video_rgb, train_video_audio, train_labels = \\\n",
    "            transform_data_for_lstm(train_video_rgb, train_video_audio, train_frame_rgb, train_frame_audio,train_labels)\n",
    "    \n",
    "    val_frame_rgb, val_frame_audio, val_video_rgb, val_video_audio, val_labels = \\\n",
    "            transform_data_for_lstm( val_video_rgb, val_video_audio,val_frame_rgb, val_frame_audio, val_labels)\n",
    "    \n",
    "    #### BELOW WE ONLY USE THE TRAINING DATA AND NO VALIDATION DATA FOR SIMPLICITY\n",
    "    df = create_pandas(train_frame_rgb, train_frame_audio, \\\n",
    "                   train_video_rgb, train_video_audio, train_labels)\n",
    "    # create spark data frame\n",
    "    if FIRST_RECORD:\n",
    "        df_spark = spark.createDataFrame(df)\n",
    "        FIRST_RECORD = False\n",
    "    else:\n",
    "        df_spark_new = spark.createDataFrame(df)\n",
    "        df_spark = df_spark.union(df_spark_new)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_data(train_frame_shards):\n",
    "    \n",
    "    NUM_RECORDS_TO_LOAD = 1\n",
    "    \n",
    "    for tf_record in tqdm(train_frame_shards[:NUM_RECORDS_TO_LOAD]):\n",
    "        # pull frames in memory\n",
    "        train_frame_ids, train_frame_labels,train_frame_rgb,train_frame_audio \\\n",
    "            = extract_frame_level_features_per_tf_record(tf_record,maximum_iter=True,\\\n",
    "                                   stop_at_iter=5) # just pull 10 videos from each tf record for debugging\n",
    "        # first transformation\n",
    "        train_video_rgb, train_video_audio, train_frame_rgb, train_frame_audio, \\\n",
    "        train_labels, val_video_rgb, val_video_audio, val_frame_rgb, val_frame_audio, val_labels \\\n",
    "                    = create_train_dev_dataset(train_mean_rgb, train_mean_audio, train_vid_ids, train_frame_rgb, \\\n",
    "                                                train_frame_audio, train_frame_labels, train_frame_ids )    \n",
    "\n",
    "        # final transformation for LSTM\n",
    "        train_frame_rgb, train_frame_audio, train_video_rgb, train_video_audio, train_labels = \\\n",
    "                transform_data_for_lstm(train_video_rgb, train_video_audio, train_frame_rgb, train_frame_audio,train_labels)\n",
    "\n",
    "        val_frame_rgb, val_frame_audio, val_video_rgb, val_video_audio, val_labels = \\\n",
    "                transform_data_for_lstm( val_video_rgb, val_video_audio,val_frame_rgb, val_frame_audio, val_labels)\n",
    "\n",
    "        #### BELOW WE ONLY USE THE TRAINING DATA AND NO VALIDATION DATA FOR SIMPLICITY\n",
    "        df = create_pandas(train_frame_rgb, train_frame_audio, \\\n",
    "                       train_video_rgb, train_video_audio, train_labels)\n",
    "        # create spark data frame\n",
    "\n",
    "        df_spark = spark.createDataFrame(df)        \n",
    "    \n",
    "        path = f\"{str(tf_record.split('/')[-1])}-converted.tfrecord\"\n",
    "        df_spark.write.format(\"tfrecords\").option(\"recordType\", \"SequenceExample\").save(path)\n",
    "        del df_spark\n",
    "        gc.collect()\n",
    "        print(path)\n",
    "        os.system(f'sudo mv {path} mys3bucket/converted_records_for_spark/')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('sudo mv train0093.tfrecord-converted.tfrecord mys3bucket/converted_records_for_spark/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1015 videos in this TF record.\n",
      "iterating video: 4 ,frames: 299/300train0093.tfrecord-converted.tfrecord\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:18<00:00, 18.15s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "convert_data(train_frame_shards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls mys3bucket/converted_records_for_spark/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"tfrecords\").option(\"recordType\", \"SequenceExample\").load('mys3bucket/converted_records_for_spark/train0093.tfrecord-converted.tfrecord/')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide list of tasks into list of lists for each core\n",
    "import multiprocessing as mp\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def chunkify_tasks(num_cores,tasks):\n",
    "    \"\"\"\n",
    "    Split a list of tasks to chunks to enable multiprocessing.\n",
    "    \"\"\"\n",
    "    num_tasks = len(tasks)\n",
    "    step = np.int(np.ceil(num_tasks / num_cores))\n",
    "    return [i for i in chunks(tasks,step)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\r\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/cpuinfo | grep processor | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mys3bucket/yt8pm_100th_shard/v2/frame/train0093.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train0111.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train0208.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train0274.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train0276.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train0352.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train0434.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train0477.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train0503.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train0580.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train0637.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train0667.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train0830.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train0979.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train1087.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train1110.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train1646.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train1745.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train1805.tfrecord',\n",
       " 'mys3bucket/yt8pm_100th_shard/v2/frame/train1864.tfrecord']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkify_tasks(4,train_frame_shards)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_multiprocess_conversion(num_cores = 4, files=None):\n",
    "                                \n",
    "    processes = []\n",
    "    chunk_files = chunkify_tasks(num_cores,files)\n",
    "\n",
    "    for i in range(num_cores): #create processes operating select image chunks (cut the list of images)\n",
    "        proc = mp.Process(target=convert_data, args=([chunk_files[i]]))\n",
    "                                                                             \n",
    "                                                                           \n",
    "        processes.append(proc)\n",
    "    return processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = prepare_multiprocess_conversion(1,files=train_frame_shards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiprocessing(processes):\n",
    "    \n",
    "    verbose = True\n",
    "    if verbose:\n",
    "        start = timeit.default_timer()\n",
    "    for p in processes:\n",
    "        p.start()\n",
    "    print('processing started...')\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    if verbose:\n",
    "        end = timeit.default_timer()\n",
    "        print(\"The running time is \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing started...\n",
      "There is 1015 videos in this TF record.\n",
      "iterating video: 0 ,frames: 0/287"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-f974d868bfad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_multiprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-68899b1337b3>\u001b[0m in \u001b[0;36mrun_multiprocessing\u001b[0;34m(processes)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_multiprocessing(processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1015 videos in this TF record.\n",
      "iterating video: 9 ,frames: 122/123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 1/2 [00:26<00:26, 26.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1029 videos in this TF record.\n",
      "iterating video: 9 ,frames: 127/128"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:50<00:00, 25.96s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "convert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          mean_audio|              labels|            mean_rgb|           frame_rgb|         frame_audio|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|[-1.1013856, -0.2...|[0.0, 0.0, 0.0, 0...|[0.30566043, 0.73...|[WrappedArray(97....|[WrappedArray(103...|\n",
      "|[0.9377164, -0.44...|[0.0, 0.0, 0.0, 1...|[0.2763526, -0.85...|[WrappedArray(0.0...|[WrappedArray(62....|\n",
      "|[-1.4782097, -0.7...|[1.0, 1.0, 0.0, 0...|[0.6331078, -0.29...|[WrappedArray(157...|[WrappedArray(66....|\n",
      "|[1.0440451, 0.883...|[0.0, 0.0, 1.0, 0...|[-0.73581076, -0....|[WrappedArray(0.0...|[WrappedArray(113...|\n",
      "|[-0.8527888, 0.96...|[0.0, 0.0, 0.0, 0...|[0.19254452, 1.00...|[WrappedArray(33....|[WrappedArray(173...|\n",
      "|[-1.070533, -0.29...|[1.0, 0.0, 0.0, 0...|[-1.100188, -0.95...|[WrappedArray(53....|[WrappedArray(101...|\n",
      "|[-0.32618448, -1....|[0.0, 0.0, 0.0, 0...|[-0.28250423, -1....|[WrappedArray(137...|[WrappedArray(131...|\n",
      "|[-0.19171691, 0.4...|[1.0, 0.0, 0.0, 0...|[0.3155772, -0.12...|[WrappedArray(149...|[WrappedArray(143...|\n",
      "|[0.9497548, 0.546...|[0.0, 0.0, 1.0, 0...|[-0.07994085, 0.0...|[WrappedArray(95....|[WrappedArray(125...|\n",
      "|[-0.56277573, -0....|[0.0, 0.0, 0.0, 0...|[0.71467525, 1.01...|[WrappedArray(172...|[WrappedArray(145...|\n",
      "|[-0.21372998, -0....|[0.0, 1.0, 1.0, 0...|[-0.30272344, -0....|[WrappedArray(0.0...|[WrappedArray(173...|\n",
      "|[0.5353788, -0.59...|[0.0, 0.0, 0.0, 0...|[-0.37246433, 0.1...|[WrappedArray(0.0...|[WrappedArray(196...|\n",
      "|[1.121538, -0.466...|[0.0, 1.0, 0.0, 0...|[-0.024919527, 0....|[WrappedArray(170...|[WrappedArray(173...|\n",
      "|[-0.97706145, -0....|[1.0, 0.0, 0.0, 0...|[-0.5987872, 0.54...|[WrappedArray(105...|[WrappedArray(155...|\n",
      "|[1.1500841, 0.016...|[0.0, 0.0, 0.0, 1...|[-0.7002603, -0.0...|[WrappedArray(0.0...|[WrappedArray(163...|\n",
      "|[-1.833181, 1.366...|[0.0, 0.0, 0.0, 0...|[0.5184007, 0.518...|[WrappedArray(175...|[WrappedArray(172...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"tfrecords\").option(\"recordType\", \"SequenceExample\").load(path)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DYLAN - YOUR JOB IS TO FIGURE OUT HOW TO RUN THE ELEPHAS TRAINING NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|         frame_audio|           frame_rgb|              labels|          mean_audio|            mean_rgb|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|[WrappedArray(173...|[WrappedArray(170...|[0.0, 1.0, 0.0, 0...|[1.12153804302215...|[-0.0249195266515...|\n",
      "|[WrappedArray(155...|[WrappedArray(105...|[1.0, 0.0, 0.0, 0...|[-0.9770614504814...|[-0.5987871885299...|\n",
      "|[WrappedArray(173...|[WrappedArray(0.0...|[0.0, 1.0, 1.0, 0...|[-0.2137299776077...|[-0.3027234375476...|\n",
      "|[WrappedArray(196...|[WrappedArray(0.0...|[0.0, 0.0, 0.0, 0...|[0.53537881374359...|[-0.3724643290042...|\n",
      "|[WrappedArray(173...|[WrappedArray(33....|[0.0, 0.0, 0.0, 0...|[-0.8527888059616...|[0.19254451990127...|\n",
      "|[WrappedArray(101...|[WrappedArray(53....|[1.0, 0.0, 0.0, 0...|[-1.0705330371856...|[-1.1001880168914...|\n",
      "|[WrappedArray(103...|[WrappedArray(97....|[0.0, 0.0, 0.0, 0...|[-1.1013855934143...|[0.30566042661666...|\n",
      "|[WrappedArray(62....|[WrappedArray(0.0...|[0.0, 0.0, 0.0, 1...|[0.93771642446517...|[0.27635261416435...|\n",
      "|[WrappedArray(125...|[WrappedArray(95....|[0.0, 0.0, 1.0, 0...|[0.94975477457046...|[-0.0799408480525...|\n",
      "|[WrappedArray(145...|[WrappedArray(172...|[0.0, 0.0, 0.0, 0...|[-0.5627757310867...|[0.71467524766922...|\n",
      "|[WrappedArray(66....|[WrappedArray(157...|[1.0, 1.0, 0.0, 0...|[-1.4782097339630...|[0.63310778141021...|\n",
      "|[WrappedArray(113...|[WrappedArray(0.0...|[0.0, 0.0, 1.0, 0...|[1.04404509067535...|[-0.7358107566833...|\n",
      "|[WrappedArray(131...|[WrappedArray(137...|[0.0, 0.0, 0.0, 0...|[-0.3261844813823...|[-0.2825042307376...|\n",
      "|[WrappedArray(143...|[WrappedArray(149...|[1.0, 0.0, 0.0, 0...|[-0.1917169094085...|[0.31557720899581...|\n",
      "|[WrappedArray(163...|[WrappedArray(0.0...|[0.0, 0.0, 0.0, 1...|[1.15008413791656...|[-0.7002602815628...|\n",
      "|[WrappedArray(172...|[WrappedArray(175...|[0.0, 0.0, 0.0, 0...|[-1.8331810235977...|[0.51840072870254...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"test-output-ALL1.tfrecord\"\n",
    "df_spark.write.format(\"tfrecords\").option(\"recordType\", \"SequenceExample\").save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          mean_audio|              labels|            mean_rgb|           frame_rgb|         frame_audio|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|[-1.1013856, -0.2...|[0.0, 0.0, 0.0, 0...|[0.30566043, 0.73...|[WrappedArray(97....|[WrappedArray(103...|\n",
      "|[0.9377164, -0.44...|[0.0, 0.0, 0.0, 1...|[0.2763526, -0.85...|[WrappedArray(0.0...|[WrappedArray(62....|\n",
      "|[-1.4782097, -0.7...|[1.0, 1.0, 0.0, 0...|[0.6331078, -0.29...|[WrappedArray(157...|[WrappedArray(66....|\n",
      "|[1.0440451, 0.883...|[0.0, 0.0, 1.0, 0...|[-0.73581076, -0....|[WrappedArray(0.0...|[WrappedArray(113...|\n",
      "|[-0.8527888, 0.96...|[0.0, 0.0, 0.0, 0...|[0.19254452, 1.00...|[WrappedArray(33....|[WrappedArray(173...|\n",
      "|[-1.070533, -0.29...|[1.0, 0.0, 0.0, 0...|[-1.100188, -0.95...|[WrappedArray(53....|[WrappedArray(101...|\n",
      "|[-0.32618448, -1....|[0.0, 0.0, 0.0, 0...|[-0.28250423, -1....|[WrappedArray(137...|[WrappedArray(131...|\n",
      "|[-0.19171691, 0.4...|[1.0, 0.0, 0.0, 0...|[0.3155772, -0.12...|[WrappedArray(149...|[WrappedArray(143...|\n",
      "|[0.9497548, 0.546...|[0.0, 0.0, 1.0, 0...|[-0.07994085, 0.0...|[WrappedArray(95....|[WrappedArray(125...|\n",
      "|[-0.56277573, -0....|[0.0, 0.0, 0.0, 0...|[0.71467525, 1.01...|[WrappedArray(172...|[WrappedArray(145...|\n",
      "|[-0.21372998, -0....|[0.0, 1.0, 1.0, 0...|[-0.30272344, -0....|[WrappedArray(0.0...|[WrappedArray(173...|\n",
      "|[0.5353788, -0.59...|[0.0, 0.0, 0.0, 0...|[-0.37246433, 0.1...|[WrappedArray(0.0...|[WrappedArray(196...|\n",
      "|[1.121538, -0.466...|[0.0, 1.0, 0.0, 0...|[-0.024919527, 0....|[WrappedArray(170...|[WrappedArray(173...|\n",
      "|[-0.97706145, -0....|[1.0, 0.0, 0.0, 0...|[-0.5987872, 0.54...|[WrappedArray(105...|[WrappedArray(155...|\n",
      "|[1.1500841, 0.016...|[0.0, 0.0, 0.0, 1...|[-0.7002603, -0.0...|[WrappedArray(0.0...|[WrappedArray(163...|\n",
      "|[-1.833181, 1.366...|[0.0, 0.0, 0.0, 0...|[0.5184007, 0.518...|[WrappedArray(175...|[WrappedArray(172...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"tfrecords\").option(\"recordType\", \"SequenceExample\").load(path)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'RDD' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-50963f89a245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'RDD' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open('sample.json', 'w') as f:\n",
    "    json.dump(json_df,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rdd = df_spark.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the order of vars to fit the order in the model!\n",
    "# train_frame_rgb, train_frame_audio, train_video_rgb, train_video_audio], train_labels\n",
    "train_rdd = train_rdd.map(lambda x: (np.array(x[1]), np.array(x[0]),np.array(x[4]),np.array(x[3]),np.array(x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anaconda2\r\n",
      "anaconda3\r\n",
      "apache-maven-3.6.1-bin.tar.gz\r\n",
      "checkpoints\r\n",
      "Classification_Tommy_2.ipynb\r\n",
      "create_and_train_biLSTM_Youtube_old.py\r\n",
      "create_and_train_biLSTM_Youtube.py\r\n",
      "derby.log\r\n",
      "ecosystem\r\n",
      "examples\r\n",
      "metastore_db\r\n",
      "mys3bucket\r\n",
      "Nvidia_Cloud_EULA.pdf\r\n",
      "Playground.ipynb\r\n",
      "__pycache__\r\n",
      "README\r\n",
      "s3fs-fuse\r\n",
      "spark-warehouse\r\n",
      "src\r\n",
      "Tensorflow-spark-connector.ipynb\r\n",
      "test-output.tfrecord\r\n",
      "test_save.txt\r\n",
      "tools\r\n",
      "train_youtube_elephas.py\r\n",
      "tutorials\r\n",
      "Youtube Classification - Frame - level.ipynb\r\n",
      "Youtube Classification - Frame - level - PMY.ipynb\r\n",
      "Youtube Classification - Frame - OLD.ipynb\r\n",
      "Youtube_video_bi-LSTM_classification.ipynb\r\n",
      "Youtube_video_bi-LSTM_classification-Spark.ipynb\r\n",
      "Youtube_video_bi-LSTM_classification-SPARK_NEW.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[170., 132.,  66., ..., 137., 135.,  40.],\n",
       "         [ 93., 153.,  75., ..., 179., 243.,  73.],\n",
       "         [118., 111.,  55., ..., 215., 160.,  59.],\n",
       "         ...,\n",
       "         [120., 106.,  73., ..., 140.,  76.,  40.],\n",
       "         [122., 173.,  73., ..., 255.,  72., 101.],\n",
       "         [137., 118.,  92., ..., 191.,  72., 158.]]),\n",
       "  array([[173.,  27., 126., ..., 133., 130., 187.],\n",
       "         [196., 101.,  42., ..., 177., 165., 255.],\n",
       "         [202.,  74.,  71., ..., 154., 151., 192.],\n",
       "         ...,\n",
       "         [161.,  79.,  95., ...,  50.,  16., 255.],\n",
       "         [130., 148.,  81., ..., 191., 152.,  52.],\n",
       "         [184.,  94.,  66., ..., 102., 193., 124.]]),\n",
       "  array([-0.02491953,  0.51688439, -0.46078882, ..., -0.28112867,\n",
       "          0.00509355, -0.0869326 ]),\n",
       "  array([ 1.12153804, -0.466645  , -0.55684108,  0.13377328,  0.21466218,\n",
       "          0.24749878,  0.01759028, -0.72384763,  0.92802167,  0.18893668,\n",
       "         -0.32677573, -0.45106331, -0.73749471,  0.24681903, -0.04980842,\n",
       "          0.13220465,  0.09779943,  0.6199432 , -0.68060583, -0.24996528,\n",
       "         -0.26554698, -0.10795221, -0.24505025, -0.90722018, -0.03987378,\n",
       "          0.16629615,  0.62334192,  0.12268832, -0.9829849 ,  0.36279288,\n",
       "          0.0174857 , -0.10220058, -0.4616777 ,  0.59949875,  0.01973407,\n",
       "          0.35301512, -0.21069731, -0.01571691, -0.22591299,  0.53210008,\n",
       "         -0.34941626,  0.31097591,  0.02799551,  0.37377328,  0.53455758,\n",
       "         -0.18136397, -0.57278883, -0.41901103,  0.20023081,  0.59400856,\n",
       "          0.09868832,  0.29047915,  0.01821773,  0.32117197,  0.17800857,\n",
       "         -0.75501102,  0.59604782,  0.29518506,  0.05999551,  0.07494976,\n",
       "          0.20043994,  0.56430924, -0.5812071 ,  0.08420466, -0.11605678,\n",
       "          0.6490674 ,  0.22553799, -0.22099796,  1.11866212,  0.33068833,\n",
       "         -0.76646203,  0.54893667,  0.32263604, -0.40107638, -0.36363849,\n",
       "         -0.4052594 , -0.18460581,  0.43615237,  0.57011318, -0.08876266,\n",
       "         -0.26722017,  0.68979943,  0.37440073,  0.8453027 , -0.31464502,\n",
       "          0.91432232, -0.11276266, -0.78936398,  0.23254453, -0.56552082,\n",
       "         -0.56050122, -0.47333783, -0.16374305,  0.44153798, -0.20729861,\n",
       "         -0.23244894, -0.37754697, -0.47239664, -0.14063194,  0.39521119,\n",
       "         -0.80980843, -0.24044894,  0.51573408, -0.48891953, -0.99166465,\n",
       "          0.30386478, -0.56640971, -0.18612213,  0.07913276, -0.46256658,\n",
       "         -0.70031822,  0.51123732, -0.01749469, -0.45869729,  0.13691054,\n",
       "          0.42532885,  0.12436152, -0.09791299, -0.39574304,  0.27149877,\n",
       "          0.28483212, -0.43631822,  0.1863223 ,  0.00744649, -0.71271038,\n",
       "         -0.00290645, -0.93582147, -0.14905025]),\n",
       "  array([0., 1., 0., 0., 1., 0., 0., 1., 0., 0.]))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rdd.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = sc.textFile('test_save.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_sample = file.flatMap(lambda line: line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(array([[',\n",
       " '97.,',\n",
       " '173.,',\n",
       " '117.,',\n",
       " '...,',\n",
       " '212.,',\n",
       " '137.,',\n",
       " '62.],',\n",
       " '[',\n",
       " '92.,',\n",
       " '173.,',\n",
       " '126.,',\n",
       " '...,',\n",
       " '227.,',\n",
       " '100.,',\n",
       " '98.],',\n",
       " '[',\n",
       " '87.,',\n",
       " '174.,',\n",
       " '120.,',\n",
       " '...,',\n",
       " '190.,',\n",
       " '98.,',\n",
       " '35.],',\n",
       " '...,',\n",
       " '[111.,',\n",
       " '173.,',\n",
       " '126.,',\n",
       " '...,',\n",
       " '166.,',\n",
       " '87.,',\n",
       " '121.],',\n",
       " '[',\n",
       " '92.,',\n",
       " '173.,',\n",
       " '124.,',\n",
       " '...,',\n",
       " '190.,',\n",
       " '28.,',\n",
       " '39.],',\n",
       " '[106.,',\n",
       " '183.,',\n",
       " '131.,',\n",
       " '...,',\n",
       " '218.,',\n",
       " '100.,',\n",
       " '78.]]),',\n",
       " 'array([[103.,',\n",
       " '60.,',\n",
       " '216.,',\n",
       " '...,',\n",
       " '99.,',\n",
       " '177.,',\n",
       " '138.],',\n",
       " '[',\n",
       " '66.,',\n",
       " '82.,',\n",
       " '249.,',\n",
       " '...,',\n",
       " '44.,',\n",
       " '170.,',\n",
       " '0.],',\n",
       " '[',\n",
       " '46.,',\n",
       " '134.,',\n",
       " '233.,',\n",
       " '...,',\n",
       " '115.,',\n",
       " '0.,',\n",
       " '255.],',\n",
       " '...,',\n",
       " '[',\n",
       " '58.,',\n",
       " '130.,',\n",
       " '221.,',\n",
       " '...,',\n",
       " '255.,',\n",
       " '161.,',\n",
       " '255.],',\n",
       " '[',\n",
       " '78.,',\n",
       " '96.,',\n",
       " '240.,',\n",
       " '...,',\n",
       " '208.,',\n",
       " '8.,',\n",
       " '255.],',\n",
       " '[',\n",
       " '46.,',\n",
       " '117.,',\n",
       " '217.,',\n",
       " '...,',\n",
       " '200.,',\n",
       " '255.,',\n",
       " '187.]]),',\n",
       " 'array([',\n",
       " '0.30566043,',\n",
       " '0.73250562,',\n",
       " '0.11245143,',\n",
       " '...,',\n",
       " '0.30170697,',\n",
       " '-0.53923041,',\n",
       " '-0.78090101]),',\n",
       " 'array([-1.10138559,',\n",
       " '-0.28021556,',\n",
       " '1.54819191,',\n",
       " '-0.73282194,',\n",
       " '-1.61826754,',\n",
       " '1.99786508,',\n",
       " '-1.58141112,',\n",
       " '1.24849474,',\n",
       " '-0.24106364,',\n",
       " '-1.9921875',\n",
       " ',',\n",
       " '0.10122873,',\n",
       " '1.79330587,',\n",
       " '0.34991357,',\n",
       " '0.25196999,',\n",
       " '1.35472786,',\n",
       " '-1.47556067,',\n",
       " '0.71108049,',\n",
       " '-0.59942484,',\n",
       " '1.86089718,',\n",
       " '-0.10358556,',\n",
       " '0.13387658,',\n",
       " '0.70100558,',\n",
       " '-0.94056946,',\n",
       " '-1.78979635,',\n",
       " '0.74117774,',\n",
       " '-0.25381669,',\n",
       " '-0.60223055,',\n",
       " '0.97774714,',\n",
       " '-0.72465998,',\n",
       " '0.5531975',\n",
       " ',',\n",
       " '1.59448552,',\n",
       " '-0.45799333,',\n",
       " '0.24368051,',\n",
       " '0.33205926,',\n",
       " '0.12482191,',\n",
       " '0.8563379',\n",
       " ',',\n",
       " '-0.71994138,',\n",
       " '-0.92947429,',\n",
       " '-1.01581252,',\n",
       " '1.7512207',\n",
       " ',',\n",
       " '1.55724657,',\n",
       " '-0.31554157,',\n",
       " '0.09561738,',\n",
       " '0.87227929,',\n",
       " '0.45232069,',\n",
       " '-1.46204245,',\n",
       " '-0.44893867,',\n",
       " '-0.67823881,',\n",
       " '-0.35456595,',\n",
       " '-0.91378802,',\n",
       " '-1.55131388,',\n",
       " '1.03156507,',\n",
       " '-0.98750073,',\n",
       " '-1.31844282,',\n",
       " '0.42171335,',\n",
       " '1.17312419,',\n",
       " '0.94560939,',\n",
       " '1.06982434,',\n",
       " '-1.60717237,',\n",
       " '-0.14630833,',\n",
       " '0.75737411,',\n",
       " '-0.19961616,',\n",
       " '0.02726093,',\n",
       " '-0.21007368,',\n",
       " '0.65739006,',\n",
       " '-0.31209823,',\n",
       " '1.06867647,',\n",
       " '1.39362466,',\n",
       " '1.28369331,',\n",
       " '-1.48117208,',\n",
       " '1.95182657,',\n",
       " '-0.54586196,',\n",
       " '-0.5359146',\n",
       " ',',\n",
       " '-1.25403988,',\n",
       " '1.14226174,',\n",
       " '1.28917706,',\n",
       " '0.0670505',\n",
       " ',',\n",
       " '-1.63344371,',\n",
       " '-0.06889721,',\n",
       " '-0.70119435,',\n",
       " '-1.0683552',\n",
       " ',',\n",
       " '0.63494468,',\n",
       " '0.65687996,',\n",
       " '-0.02961776,',\n",
       " '0.6876148',\n",
       " ',',\n",
       " '0.05901607,',\n",
       " '0.99547392,',\n",
       " '0.00456047,',\n",
       " '-0.71165186,',\n",
       " '0.36508971,',\n",
       " '-0.36795667,',\n",
       " '0.69309866,',\n",
       " '-0.77733016,',\n",
       " '-0.15842375,',\n",
       " '0.52118731,',\n",
       " '-0.5422911',\n",
       " ',',\n",
       " '1.2097255',\n",
       " ',',\n",
       " '0.22710152,',\n",
       " '-0.85321093,',\n",
       " '-1.08187342,',\n",
       " '-1.37965763,',\n",
       " '0.98272085,',\n",
       " '0.05161929,',\n",
       " '-0.65490073,',\n",
       " '0.31892362,',\n",
       " '1.03386068,',\n",
       " '-0.99476999,',\n",
       " '0.00443294,',\n",
       " '1.32743633,',\n",
       " '0.90339673,',\n",
       " '1.39745069,',\n",
       " '0.10352428,',\n",
       " '-1.18300533,',\n",
       " '-1.41141272,',\n",
       " '-0.37191013,',\n",
       " '-0.57519406,',\n",
       " '-0.87578386,',\n",
       " '0.42247853,',\n",
       " '0.63086367,',\n",
       " '0.4838208',\n",
       " ',',\n",
       " '1.52918983,',\n",
       " '-1.61265612,',\n",
       " '-0.60937226,',\n",
       " '0.41788742,',\n",
       " '0.98437876,',\n",
       " '0.77599359,',\n",
       " '0.20248809,',\n",
       " '1.06127977]),',\n",
       " 'array([0.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '1.,',\n",
       " '0.]))',\n",
       " '(array([[',\n",
       " '0.,',\n",
       " '72.,',\n",
       " '173.,',\n",
       " '...,',\n",
       " '142.,',\n",
       " '119.,',\n",
       " '137.],',\n",
       " '[',\n",
       " '54.,',\n",
       " '115.,',\n",
       " '90.,',\n",
       " '...,',\n",
       " '39.,',\n",
       " '153.,',\n",
       " '255.],',\n",
       " '[',\n",
       " '91.,',\n",
       " '106.,',\n",
       " '90.,',\n",
       " '...,',\n",
       " '46.,',\n",
       " '108.,',\n",
       " '186.],',\n",
       " '...,',\n",
       " '[131.,',\n",
       " '121.,',\n",
       " '108.,',\n",
       " '...,',\n",
       " '59.,',\n",
       " '147.,',\n",
       " '108.],',\n",
       " '[',\n",
       " '0.,',\n",
       " '72.,',\n",
       " '173.,',\n",
       " '...,',\n",
       " '142.,',\n",
       " '119.,',\n",
       " '137.],',\n",
       " '[',\n",
       " '0.,',\n",
       " '72.,',\n",
       " '173.,',\n",
       " '...,',\n",
       " '142.,',\n",
       " '119.,',\n",
       " '137.]]),',\n",
       " 'array([[',\n",
       " '62.,',\n",
       " '140.,',\n",
       " '0.,',\n",
       " '...,',\n",
       " '0.,',\n",
       " '185.,',\n",
       " '24.],',\n",
       " '[',\n",
       " '75.,',\n",
       " '194.,',\n",
       " '0.,',\n",
       " '...,',\n",
       " '0.,',\n",
       " '255.,',\n",
       " '0.],',\n",
       " '[',\n",
       " '93.,',\n",
       " '108.,',\n",
       " '37.,',\n",
       " '...,',\n",
       " '0.,',\n",
       " '195.,',\n",
       " '0.],',\n",
       " '...,',\n",
       " '[173.,',\n",
       " '27.,',\n",
       " '126.,',\n",
       " '...,',\n",
       " '133.,',\n",
       " '130.,',\n",
       " '187.],',\n",
       " '[153.,',\n",
       " '72.,',\n",
       " '100.,',\n",
       " '...,',\n",
       " '95.,',\n",
       " '83.,',\n",
       " '148.],',\n",
       " '[184.,',\n",
       " '40.,',\n",
       " '122.,',\n",
       " '...,',\n",
       " '155.,',\n",
       " '78.,',\n",
       " '217.]]),',\n",
       " 'array([',\n",
       " '0.27635261,',\n",
       " '-0.85204303,',\n",
       " '0.16159515,',\n",
       " '...,',\n",
       " '-0.13568199,',\n",
       " '0.13873257,',\n",
       " '-0.01584393]),',\n",
       " 'array([',\n",
       " '0.93771642,',\n",
       " '-0.44508898,',\n",
       " '-0.94349337,',\n",
       " '0.55464113,',\n",
       " '0.21201985,',\n",
       " '0.90640742,',\n",
       " '-0.19258443,',\n",
       " '-0.54085779,',\n",
       " '0.70032656,',\n",
       " '0.38698214,',\n",
       " '0.48256046,',\n",
       " '-0.5406673',\n",
       " ',',\n",
       " '0.83407271,',\n",
       " '-0.78110552,',\n",
       " '0.5183785',\n",
       " ',',\n",
       " '1.2164495',\n",
       " ',',\n",
       " '-1.06644332,',\n",
       " '-0.11180328,',\n",
       " '0.46769977,',\n",
       " '1.42532456,',\n",
       " '0.6501559',\n",
       " ',',\n",
       " '0.16832691,',\n",
       " '-0.18439199,',\n",
       " '1.11871195,',\n",
       " '0.46109504,',\n",
       " '0.60341465,',\n",
       " '0.10246996,',\n",
       " '0.99912786,',\n",
       " '0.31210718,',\n",
       " '0.95664161,',\n",
       " '0.18267953,',\n",
       " '-0.45734587,',\n",
       " '0.66101563,',\n",
       " '-0.6326257',\n",
       " ',',\n",
       " '0.49678606,',\n",
       " '0.27133557,',\n",
       " '-0.61274797,',\n",
       " '-0.04429514,',\n",
       " '0.98852217,',\n",
       " '-0.30442056,',\n",
       " '1.13979626,',\n",
       " '0.40508169,',\n",
       " '-0.08513027,',\n",
       " '-0.43607098,',\n",
       " '-0.03889703,',\n",
       " '0.44515473,',\n",
       " '-0.45391649,',\n",
       " '0.10526428,',\n",
       " '0.36964467,',\n",
       " '-0.79361641,',\n",
       " '-0.24656552,',\n",
       " '0.1373354',\n",
       " ',',\n",
       " '0.41575089,',\n",
       " '-0.02327427,',\n",
       " '0.40292245,',\n",
       " '0.70521665,',\n",
       " '0.18604541,',\n",
       " '-0.53996873,',\n",
       " '0.26003128,',\n",
       " '0.67663842,',\n",
       " '-0.27234945,',\n",
       " '0.6828621',\n",
       " ',',\n",
       " '-0.14952655,',\n",
       " '0.42318124,',\n",
       " '-0.26777694,',\n",
       " '1.25887227,',\n",
       " '-1.0584414',\n",
       " ',',\n",
       " '0.7155683',\n",
       " ',',\n",
       " '0.59026861,',\n",
       " '-0.11447059,',\n",
       " '-0.58181995,',\n",
       " '-0.33077607,',\n",
       " '1.04097915,',\n",
       " '-0.05102691,',\n",
       " '-0.90723073,',\n",
       " '-1.20800078,',\n",
       " '0.13403302,',\n",
       " '0.27514598,',\n",
       " '-0.11205731,',\n",
       " '0.26949385,',\n",
       " '-0.53349096,',\n",
       " '1.02815068,',\n",
       " '-0.02911693,',\n",
       " '0.40209687,',\n",
       " '-0.47512788,',\n",
       " '-0.71772534,',\n",
       " '0.66019005,',\n",
       " '0.48878416,',\n",
       " '-1.13820636,',\n",
       " '-0.16851519,',\n",
       " '-0.81063634,',\n",
       " '-0.5918541',\n",
       " ',',\n",
       " '0.63294548,',\n",
       " '-0.49824449,',\n",
       " '0.38380679,',\n",
       " '0.18248901,',\n",
       " '0.77818638,',\n",
       " '0.42667413,',\n",
       " '-0.62640202,',\n",
       " '-0.10297579,',\n",
       " '-0.53577727,',\n",
       " '1.01868808,',\n",
       " '1.21060681,',\n",
       " '0.32995269,',\n",
       " '-0.28822625,',\n",
       " '0.32614225,',\n",
       " '-0.21925744,',\n",
       " '0.8037163',\n",
       " ',',\n",
       " '-0.55635357,',\n",
       " '1.04758382,',\n",
       " '0.61097199,',\n",
       " '-0.7634505',\n",
       " ',',\n",
       " '0.49754816,',\n",
       " '1.11121809,',\n",
       " '0.08970501,',\n",
       " '-0.33357036,',\n",
       " '-0.82276618,',\n",
       " '-0.95168579,',\n",
       " '-0.8669672',\n",
       " ',',\n",
       " '0.2186881',\n",
       " ',',\n",
       " '0.80943191,',\n",
       " '-0.73372912,',\n",
       " '0.29953274,',\n",
       " '-0.03953211,',\n",
       " '-0.81997192,',\n",
       " '-0.64412051,',\n",
       " '-0.3046746',\n",
       " ',',\n",
       " '-0.41727284]),',\n",
       " 'array([0.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '1.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '0.]))',\n",
       " '(array([[170.,',\n",
       " '132.,',\n",
       " '66.,',\n",
       " '...,',\n",
       " '137.,',\n",
       " '135.,',\n",
       " '40.],',\n",
       " '[',\n",
       " '93.,',\n",
       " '153.,',\n",
       " '75.,',\n",
       " '...,',\n",
       " '179.,',\n",
       " '243.,',\n",
       " '73.],',\n",
       " '[118.,',\n",
       " '111.,',\n",
       " '55.,',\n",
       " '...,',\n",
       " '215.,',\n",
       " '160.,',\n",
       " '59.],',\n",
       " '...,',\n",
       " '[120.,',\n",
       " '106.,',\n",
       " '73.,',\n",
       " '...,',\n",
       " '140.,',\n",
       " '76.,',\n",
       " '40.],',\n",
       " '[122.,',\n",
       " '173.,',\n",
       " '73.,',\n",
       " '...,',\n",
       " '255.,',\n",
       " '72.,',\n",
       " '101.],',\n",
       " '[137.,',\n",
       " '118.,',\n",
       " '92.,',\n",
       " '...,',\n",
       " '191.,',\n",
       " '72.,',\n",
       " '158.]]),',\n",
       " 'array([[173.,',\n",
       " '27.,',\n",
       " '126.,',\n",
       " '...,',\n",
       " '133.,',\n",
       " '130.,',\n",
       " '187.],',\n",
       " '[196.,',\n",
       " '101.,',\n",
       " '42.,',\n",
       " '...,',\n",
       " '177.,',\n",
       " '165.,',\n",
       " '255.],',\n",
       " '[202.,',\n",
       " '74.,',\n",
       " '71.,',\n",
       " '...,',\n",
       " '154.,',\n",
       " '151.,',\n",
       " '192.],',\n",
       " '...,',\n",
       " '[161.,',\n",
       " '79.,',\n",
       " '95.,',\n",
       " '...,',\n",
       " '50.,',\n",
       " '16.,',\n",
       " '255.],',\n",
       " '[130.,',\n",
       " '148.,',\n",
       " '81.,',\n",
       " '...,',\n",
       " '191.,',\n",
       " '152.,',\n",
       " '52.],',\n",
       " '[184.,',\n",
       " '94.,',\n",
       " '66.,',\n",
       " '...,',\n",
       " '102.,',\n",
       " '193.,',\n",
       " '124.]]),',\n",
       " 'array([-0.02491953,',\n",
       " '0.51688439,',\n",
       " '-0.46078882,',\n",
       " '...,',\n",
       " '-0.28112867,',\n",
       " '0.00509355,',\n",
       " '-0.0869326',\n",
       " ']),',\n",
       " 'array([',\n",
       " '1.12153804,',\n",
       " '-0.466645',\n",
       " ',',\n",
       " '-0.55684108,',\n",
       " '0.13377328,',\n",
       " '0.21466218,',\n",
       " '0.24749878,',\n",
       " '0.01759028,',\n",
       " '-0.72384763,',\n",
       " '0.92802167,',\n",
       " '0.18893668,',\n",
       " '-0.32677573,',\n",
       " '-0.45106331,',\n",
       " '-0.73749471,',\n",
       " '0.24681903,',\n",
       " '-0.04980842,',\n",
       " '0.13220465,',\n",
       " '0.09779943,',\n",
       " '0.6199432',\n",
       " ',',\n",
       " '-0.68060583,',\n",
       " '-0.24996528,',\n",
       " '-0.26554698,',\n",
       " '-0.10795221,',\n",
       " '-0.24505025,',\n",
       " '-0.90722018,',\n",
       " '-0.03987378,',\n",
       " '0.16629615,',\n",
       " '0.62334192,',\n",
       " '0.12268832,',\n",
       " '-0.9829849',\n",
       " ',',\n",
       " '0.36279288,',\n",
       " '0.0174857',\n",
       " ',',\n",
       " '-0.10220058,',\n",
       " '-0.4616777',\n",
       " ',',\n",
       " '0.59949875,',\n",
       " '0.01973407,',\n",
       " '0.35301512,',\n",
       " '-0.21069731,',\n",
       " '-0.01571691,',\n",
       " '-0.22591299,',\n",
       " '0.53210008,',\n",
       " '-0.34941626,',\n",
       " '0.31097591,',\n",
       " '0.02799551,',\n",
       " '0.37377328,',\n",
       " '0.53455758,',\n",
       " '-0.18136397,',\n",
       " '-0.57278883,',\n",
       " '-0.41901103,',\n",
       " '0.20023081,',\n",
       " '0.59400856,',\n",
       " '0.09868832,',\n",
       " '0.29047915,',\n",
       " '0.01821773,',\n",
       " '0.32117197,',\n",
       " '0.17800857,',\n",
       " '-0.75501102,',\n",
       " '0.59604782,',\n",
       " '0.29518506,',\n",
       " '0.05999551,',\n",
       " '0.07494976,',\n",
       " '0.20043994,',\n",
       " '0.56430924,',\n",
       " '-0.5812071',\n",
       " ',',\n",
       " '0.08420466,',\n",
       " '-0.11605678,',\n",
       " '0.6490674',\n",
       " ',',\n",
       " '0.22553799,',\n",
       " '-0.22099796,',\n",
       " '1.11866212,',\n",
       " '0.33068833,',\n",
       " '-0.76646203,',\n",
       " '0.54893667,',\n",
       " '0.32263604,',\n",
       " '-0.40107638,',\n",
       " '-0.36363849,',\n",
       " '-0.4052594',\n",
       " ',',\n",
       " '-0.18460581,',\n",
       " '0.43615237,',\n",
       " '0.57011318,',\n",
       " '-0.08876266,',\n",
       " '-0.26722017,',\n",
       " '0.68979943,',\n",
       " '0.37440073,',\n",
       " '0.8453027',\n",
       " ',',\n",
       " '-0.31464502,',\n",
       " '0.91432232,',\n",
       " '-0.11276266,',\n",
       " '-0.78936398,',\n",
       " '0.23254453,',\n",
       " '-0.56552082,',\n",
       " '-0.56050122,',\n",
       " '-0.47333783,',\n",
       " '-0.16374305,',\n",
       " '0.44153798,',\n",
       " '-0.20729861,',\n",
       " '-0.23244894,',\n",
       " '-0.37754697,',\n",
       " '-0.47239664,',\n",
       " '-0.14063194,',\n",
       " '0.39521119,',\n",
       " '-0.80980843,',\n",
       " '-0.24044894,',\n",
       " '0.51573408,',\n",
       " '-0.48891953,',\n",
       " '-0.99166465,',\n",
       " '0.30386478,',\n",
       " '-0.56640971,',\n",
       " '-0.18612213,',\n",
       " '0.07913276,',\n",
       " '-0.46256658,',\n",
       " '-0.70031822,',\n",
       " '0.51123732,',\n",
       " '-0.01749469,',\n",
       " '-0.45869729,',\n",
       " '0.13691054,',\n",
       " '0.42532885,',\n",
       " '0.12436152,',\n",
       " '-0.09791299,',\n",
       " '-0.39574304,',\n",
       " '0.27149877,',\n",
       " '0.28483212,',\n",
       " '-0.43631822,',\n",
       " '0.1863223',\n",
       " ',',\n",
       " '0.00744649,',\n",
       " '-0.71271038,',\n",
       " '-0.00290645,',\n",
       " '-0.93582147,',\n",
       " '-0.14905025]),',\n",
       " 'array([0.,',\n",
       " '1.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '1.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '1.,',\n",
       " '0.,',\n",
       " '0.]))',\n",
       " '(array([[105.,',\n",
       " '185.,',\n",
       " '94.,',\n",
       " '...,',\n",
       " '122.,',\n",
       " '95.,',\n",
       " '12.],',\n",
       " '[',\n",
       " '78.,',\n",
       " '196.,',\n",
       " '102.,',\n",
       " '...,',\n",
       " '94.,',\n",
       " '59.,',\n",
       " '18.],',\n",
       " '[',\n",
       " '68.,',\n",
       " '175.,',\n",
       " '123.,',\n",
       " '...,',\n",
       " '140.,',\n",
       " '99.,',\n",
       " '0.],',\n",
       " '...,',\n",
       " '[',\n",
       " '78.,',\n",
       " '197.,',\n",
       " '99.,',\n",
       " '...,',\n",
       " '94.,',\n",
       " '19.,',\n",
       " '35.],',\n",
       " '[',\n",
       " '62.,',\n",
       " '193.,',\n",
       " '98.,',\n",
       " '...,',\n",
       " '115.,',\n",
       " '51.,',\n",
       " '4.],',\n",
       " '[',\n",
       " '82.,',\n",
       " '187.,',\n",
       " '105.,',\n",
       " '...,',\n",
       " '135.,',\n",
       " '26.,',\n",
       " '45.]]),',\n",
       " 'array([[155.,',\n",
       " '67.,',\n",
       " '138.,',\n",
       " '...,',\n",
       " '251.,',\n",
       " '104.,',\n",
       " '255.],',\n",
       " '[',\n",
       " '96.,',\n",
       " '63.,',\n",
       " '128.,',\n",
       " '...,',\n",
       " '15.,',\n",
       " '127.,',\n",
       " '255.],',\n",
       " '[106.,',\n",
       " '43.,',\n",
       " '136.,',\n",
       " '...,',\n",
       " '57.,',\n",
       " '185.,',\n",
       " '255.],',\n",
       " '...,',\n",
       " '[102.,',\n",
       " '54.,',\n",
       " '118.,',\n",
       " '...,',\n",
       " '255.,',\n",
       " '255.,',\n",
       " '165.],',\n",
       " '[',\n",
       " '63.,',\n",
       " '88.,',\n",
       " '154.,',\n",
       " '...,',\n",
       " '178.,',\n",
       " '149.,',\n",
       " '215.],',\n",
       " '[',\n",
       " '55.,',\n",
       " '108.,',\n",
       " '102.,',\n",
       " '...,',\n",
       " '255.,',\n",
       " '156.,',\n",
       " '137.]]),',\n",
       " 'array([-0.59878719,',\n",
       " '0.54188371,',\n",
       " '-0.4125742',\n",
       " ',',\n",
       " '...,',\n",
       " '0.16617829,',\n",
       " '-0.15689339,',\n",
       " '-0.79205084]),',\n",
       " 'array([-0.97706145,',\n",
       " '-0.33654767,',\n",
       " '-1.12916911,',\n",
       " '0.22165413,',\n",
       " '0.01232162,',\n",
       " '0.36884278,',\n",
       " '-0.38475427,',\n",
       " '-0.95601887,',\n",
       " '-1.15349102,',\n",
       " '-0.58435804,',\n",
       " '1.29542613,',\n",
       " '-0.94694597,',\n",
       " '-1.45754242,',\n",
       " '-0.27806574,',\n",
       " '-0.69033605,',\n",
       " '-0.84036678,',\n",
       " '-1.03199077,',\n",
       " '-1.62506306,',\n",
       " '0.92999601,',\n",
       " '-1.58609331,',\n",
       " '-0.38612068,',\n",
       " '-0.47777882,',\n",
       " '-0.39962071,',\n",
       " '-1.16666317,',\n",
       " '-1.24126863,',\n",
       " '1.63309085,',\n",
       " '1.58537626,',\n",
       " '1.19578815,',\n",
       " '1.42998922,',\n",
       " '1.19278204,',\n",
       " '-0.84342748,',\n",
       " '-0.8404761',\n",
       " ',',\n",
       " '1.15960586,',\n",
       " '-0.87119275,',\n",
       " '0.7226311',\n",
       " ',',\n",
       " '0.55423594,',\n",
       " '1.47398722,',\n",
       " '0.28680411,',\n",
       " '-0.96700472,',\n",
       " '0.72957242,',\n",
       " '0.17645362,',\n",
       " '0.5667522',\n",
       " ',',\n",
       " '1.4079628',\n",
       " ',',\n",
       " '1.30089164,',\n",
       " '-1.86429238,',\n",
       " '-1.41141272,',\n",
       " '1.36396468,',\n",
       " '0.57467729,',\n",
       " '-0.98400277,',\n",
       " '-0.29632086,',\n",
       " '1.22830856,',\n",
       " '-0.61884594,',\n",
       " '0.75460488,',\n",
       " '-0.77013379,',\n",
       " '-1.22356009,',\n",
       " '0.73476475,',\n",
       " '-0.3238675',\n",
       " ',',\n",
       " '1.32286334,',\n",
       " '1.29712045,',\n",
       " '0.79690862,',\n",
       " '0.40628213,',\n",
       " '-1.11315489,',\n",
       " '-0.87419885,',\n",
       " '1.49185979,',\n",
       " '-0.40852964,',\n",
       " '-0.19411412,',\n",
       " '-0.642676',\n",
       " ',',\n",
       " '-1.51963162,',\n",
       " '0.25794572,',\n",
       " '-0.45799333,',\n",
       " '-0.56533772,',\n",
       " '-0.70279759,',\n",
       " '-1.01832676,',\n",
       " '-1.14895463,',\n",
       " '0.37332457,',\n",
       " '-0.31342819,',\n",
       " '0.66458642,',\n",
       " '-1.33385587,',\n",
       " '0.40874165,',\n",
       " '-1.36752403,',\n",
       " '1.35729671,',\n",
       " '-0.43159449,',\n",
       " '-1.47142506,',\n",
       " '-0.49800155,',\n",
       " '-0.25598472,',\n",
       " '0.7169469',\n",
       " ',',\n",
       " '1.12397015,',\n",
       " '0.082172',\n",
       " ',',\n",
       " '1.38200116,',\n",
       " '1.23574173,',\n",
       " '0.38086709,',\n",
       " '1.69091702,',\n",
       " '-0.42864305,',\n",
       " '-1.68163204,',\n",
       " '-1.36861706,',\n",
       " '-1.13649297,',\n",
       " '-1.01931059,',\n",
       " '0.98842329,',\n",
       " '1.23426604,',\n",
       " '0.86736023,',\n",
       " '0.35976988,',\n",
       " '0.40371329,',\n",
       " '0.7941758',\n",
       " ',',\n",
       " '-1.08200097,',\n",
       " '-0.57370013,',\n",
       " '-1.05150294,',\n",
       " '1.29362237,',\n",
       " '0.06522863,',\n",
       " '-0.73253047,',\n",
       " '0.10501821,',\n",
       " '-0.66738051,',\n",
       " '0.8278439',\n",
       " ',',\n",
       " '-1.46218812,',\n",
       " '1.58958471,',\n",
       " '-0.54582554,',\n",
       " '-0.87490934,',\n",
       " '-0.00965009,',\n",
       " '-1.41321635,',\n",
       " '0.44257373,',\n",
       " '0.71027887,',\n",
       " '0.7324692',\n",
       " ',',\n",
       " '-1.11594236,',\n",
       " '0.74137813,',\n",
       " '-1.6971544',\n",
       " ',',\n",
       " '0.39589748,',\n",
       " '0.98399615,',\n",
       " '1.53509271,',\n",
       " '0.35938728]),',\n",
       " 'array([1.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '0.,',\n",
       " '1.,',\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_sample.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10, 1024)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 10, 128)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 200)          900000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 200)          183200      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1024)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 400)          0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 500)          512500      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400)          1600        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500)          2000        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 400)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 500)          200500      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 500)          250500      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000)         0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1000)         4000        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000)         0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1000)         1001000     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1000)         4000        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1000)         0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           10010       dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,069,310\n",
      "Trainable params: 3,063,510\n",
      "Non-trainable params: 5,800\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "keras_model= create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_model = SparkModel(keras_model, frequency='batch', mode='synchronous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Fit model\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 5.0 failed 1 times, most recent failure: Lost task 3.0 in stage 5.0 (TID 20, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/worker.py\", line 36, in train\n    x_train = np.asarray([x for x, y in feature_iterator])\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/worker.py\", line 36, in <listcomp>\n    x_train = np.asarray([x for x, y in feature_iterator])\nValueError: too many values to unpack (expected 2)\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2050)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2069)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2094)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:935)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:467)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/worker.py\", line 36, in train\n    x_train = np.asarray([x for x, y in feature_iterator])\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/worker.py\", line 36, in <listcomp>\n    x_train = np.asarray([x for x, y in feature_iterator])\nValueError: too many values to unpack (expected 2)\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-27dfe73abae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_rdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/spark_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, rdd, epochs, batch_size, verbose, validation_split)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'asynchronous'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'synchronous'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hogwild'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/spark_model.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, rdd, epochs, batch_size, verbose, validation_split)\u001b[0m\n\u001b[1;32m    186\u001b[0m             worker = SparkWorker(yaml, parameters, train_config,\n\u001b[1;32m    187\u001b[0m                                  optimizer, loss, metrics, custom)\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0mnew_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_master_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# simply accumulate gradients one by one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 5.0 failed 1 times, most recent failure: Lost task 3.0 in stage 5.0 (TID 20, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/worker.py\", line 36, in train\n    x_train = np.asarray([x for x, y in feature_iterator])\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/worker.py\", line 36, in <listcomp>\n    x_train = np.asarray([x for x, y in feature_iterator])\nValueError: too many values to unpack (expected 2)\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2050)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2069)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2094)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:935)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:467)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/worker.py\", line 36, in train\n    x_train = np.asarray([x for x, y in feature_iterator])\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/worker.py\", line 36, in <listcomp>\n    x_train = np.asarray([x for x, y in feature_iterator])\nValueError: too many values to unpack (expected 2)\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# HOW TO MAKE SURE THIS WORKS???\n",
    "history = spark_model.fit(train_rdd, epochs=10, batch_size=2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
