{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from IPython.display import YouTubeVideo\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try just using Video-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos in Sample data set: 41393\n",
      "Picking a youtube video id: YwbF\n",
      "List of label ids for youtube video id YwbF, are - [0, 12]\n",
      "First 20 rgb feature of a youtube video ( YwbF ): are - [0.7414522171020508, -1.0128370523452759, -0.2103247493505478, -0.6396752595901489, -0.8331801295280457, -0.0706188753247261, 1.1849571466445923, -0.6760722994804382, -0.969638466835022, 0.08704043924808502, 1.6186580657958984, 0.8913909196853638, 0.05266544222831726, 0.7622855305671692, -1.2969056367874146, 1.1235600709915161, 0.08802083134651184, -0.42791053652763367, 1.0219056606292725, -0.6768688559532166]\n"
     ]
    }
   ],
   "source": [
    "# distribution of labels\n",
    "video_files = glob(\"mys3bucket/yt8pm_100th_shard/v2/video/train*\")\n",
    "\n",
    "vid_ids = []\n",
    "labels = []\n",
    "mean_rgb = []\n",
    "mean_audio = []\n",
    "\n",
    "for file in video_files:\n",
    "    for example in tf.python_io.tf_record_iterator(file):\n",
    "        tf_example = tf.train.Example.FromString(example)\n",
    "\n",
    "        vid_ids.append(tf_example.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8'))\n",
    "        labels.append(tf_example.features.feature['labels'].int64_list.value)\n",
    "        mean_rgb.append(tf_example.features.feature['mean_rgb'].float_list.value)\n",
    "        mean_audio.append(tf_example.features.feature['mean_audio'].float_list.value)\n",
    "\n",
    "print('Number of videos in Sample data set: %s' % str(len(vid_ids)))\n",
    "print('Picking a youtube video id: %s' % vid_ids[13])\n",
    "print('List of label ids for youtube video id %s, are - %s' % (vid_ids[13], str(labels[13])))\n",
    "print('First 20 rgb feature of a youtube video (',vid_ids[13],'): are - %s' % str(mean_rgb[13][:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-LSTM video classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILIP : not really bi-LSTM without the temporal aspect of frame-level features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# keras imports\n",
    "from keras.layers import Dense, Input, LSTM, Dropout, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "import operator\n",
    "import time \n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating training and dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_dev_dataset(video_rgb, video_audio, labels):\n",
    "    \"\"\"\n",
    "    Method to created training and validation data\n",
    "    \"\"\"\n",
    "    \n",
    "    #Convert video and audio data to np.arrays:\n",
    "    video_rgb = np.array(video_rgb)\n",
    "    video_audio = np.array(video_audio)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    shuffle_indices = np.random.permutation(np.arange(len(labels)))\n",
    "    video_rgb_shuffled = video_rgb[shuffle_indices]\n",
    "    video_audio_shuffled = video_audio[shuffle_indices]\n",
    "    labels_shuffled = labels[shuffle_indices]\n",
    "\n",
    "    dev_idx = max(1, int(len(labels_shuffled) * validation_split_ratio))\n",
    "\n",
    "    del video_rgb\n",
    "    del video_audio\n",
    "    gc.collect()\n",
    "\n",
    "    train_video_rgb, val_video_rgb = video_rgb_shuffled[:-dev_idx], video_rgb_shuffled[-dev_idx:]\n",
    "    train_video_audio, val_video_audio = video_audio_shuffled[:-dev_idx], video_audio_shuffled[-dev_idx:]\n",
    "    \n",
    "    train_labels, val_labels = labels_shuffled[:-dev_idx], labels_shuffled[-dev_idx:]\n",
    "    \n",
    "    del video_rgb_shuffled, video_audio_shuffled, labels_shuffled\n",
    "    gc.collect()\n",
    "    \n",
    "    return (train_video_rgb, train_video_audio, train_labels, val_video_rgb, val_video_audio, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining Model parameters and creating architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TOMMY: Try specifying an input shape for each of these\n",
    "\n",
    "max_frame_rgb_sequence_length = 10\n",
    "frame_rgb_embedding_size = 1024\n",
    "\n",
    "max_frame_audio_sequence_length = 10\n",
    "frame_audio_embedding_size = 128\n",
    "\n",
    "number_dense_units = 1000\n",
    "number_lstm_units = 100\n",
    "rate_drop_lstm = 0.2\n",
    "rate_drop_dense = 0.2\n",
    "activation_function='relu'\n",
    "validation_split_ratio = 0.2\n",
    "\n",
    "label_feature_size = 20\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"Create and store best model at `checkpoint` path ustilising bi-lstm layer for frame level data of videos\"\"\"\n",
    "    # Filip: without the frame-level data, we don't actually have a bi-LSTM\n",
    "    \n",
    "    # Creating 2 bi-lstm layer, one for rgb and other for audio level data\n",
    "#     lstm_layer_1 = Bidirectional(LSTM(number_lstm_units, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
    "#     lstm_layer_2 = Bidirectional(LSTM(number_lstm_units, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
    "    \n",
    "    # creating input layer for frame-level data\n",
    "    # FILIP: these below are frame-level features\n",
    "#     frame_rgb_sequence_input = Input(shape=(max_frame_rgb_sequence_length, frame_rgb_embedding_size), dtype='float32')\n",
    "#     frame_audio_sequence_input = Input(shape=(max_frame_audio_sequence_length, frame_audio_embedding_size), dtype='float32')\n",
    "    \n",
    "#     frame_x1 = lstm_layer_1(frame_rgb_sequence_input)\n",
    "#     frame_x2 = lstm_layer_2(frame_audio_sequence_input)\n",
    "    \n",
    "    ### - Below un-deleted\n",
    "    #creating input layer for video-level data \n",
    "    vid_shape=(1024,)\n",
    "    video_rgb_input = Input(shape=vid_shape)\n",
    "#     vid_rgb_shape = video_rgb_input[0].shape ###TOMMY\n",
    "#     print(vid_rgb_shape)\n",
    "    video_rgb_dense = Dense(int(number_dense_units/2), activation=activation_function, input_shape=vid_shape)(video_rgb_input)\n",
    "    \n",
    "#     aud_shape=(128,)\n",
    "#     video_audio_input = Input(shape=aud_shape)\n",
    "# #     vid_audio_shape = tf.cast(video_audio_input[0].shape, tf.int64) ###TOMMY\n",
    "#     video_audio_dense = Dense(int(number_dense_units/2), activation=activation_function,input_shape = aud_shape)(video_audio_input)\n",
    "#     ### - Above un-deleted\n",
    "    \n",
    "    # merging frame-level bi-lstm output and later passed to dense layer by applying batch-normalisation and dropout\n",
    "#     merged_frame = concatenate([frame_x1, frame_x2])\n",
    "#     merged_frame = BatchNormalization()(merged_frame)\n",
    "#     merged_frame = Dropout(rate_drop_dense)(merged_frame)\n",
    "#     merged_frame_dense = Dense(int(number_dense_units/2), activation=activation_function)(merged_frame)\n",
    "    \n",
    "    \n",
    "    ### - Below un-deleted\n",
    "    # merging video-level dense layer output\n",
    "#     merged_video = concatenate([video_rgb_dense, video_audio_dense])\n",
    "    merged_video = BatchNormalization()(video_rgb_dense)\n",
    "    merged_video = Dropout(rate_drop_dense)(merged_video)\n",
    "    merged_video_dense = Dense(int(number_dense_units/2), activation=activation_function)(merged_video)\n",
    "    ### - Above un-deleted\n",
    "    \n",
    "    # merging frame-level and video-level dense layer output\n",
    "    merged = merged_video_dense#merged_frame_dense#concatenate([merged_frame_dense, merged_video_dense])\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dropout(rate_drop_dense)(merged)\n",
    "     \n",
    "    merged = Dense(number_dense_units, activation=activation_function)(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dropout(rate_drop_dense)(merged)\n",
    "    preds = Dense(label_feature_size, activation='sigmoid')(merged)\n",
    "    \n",
    "    model = Model(inputs=video_rgb_input, outputs=preds)\n",
    "    print(model.summary())\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['acc'])\n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    \n",
    "#     STAMP = 'lstm_%d_%d_%.2f_%.2f' % (number_lstm_units, number_dense_units, rate_drop_lstm, rate_drop_dense)\n",
    "\n",
    "#     checkpoint_dir = 'checkpoints/' + str(int(time.time())) + '/'\n",
    "\n",
    "#     if not os.path.exists(checkpoint_dir):\n",
    "#         os.makedirs(checkpoint_dir)\n",
    "\n",
    "#     bst_model_path = checkpoint_dir + STAMP + '.h5'\n",
    "#     model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)\n",
    "#     tensorboard = TensorBoard(log_dir=checkpoint_dir + \"logs/{}\".format(time.time()))\n",
    "    \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(video_rgb, video_audio, labels):\n",
    "    return create_train_dev_dataset(video_rgb, video_audio, labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_rgb = mean_rgb\n",
    "video_audio = mean_audio\n",
    "vid_ids = vid_ids\n",
    "\n",
    "# frame_rgb = feat_rgb\n",
    "# frame_audio = feat_audio\n",
    "labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'video_rgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-74ed5a0581c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_or_indexed_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_rgb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'video_rgb' is not defined"
     ]
    }
   ],
   "source": [
    "number = tf.convert_to_tensor_or_indexed_slices(video_rgb[0][1],dtype=tf.float32)\n",
    "tf.Session().run(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               512500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              501000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                20020     \n",
      "=================================================================\n",
      "Total params: 1,292,020\n",
      "Trainable params: 1,288,020\n",
      "Non-trainable params: 4,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.types import *\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster('local').setAppName('TFrecords_loading').set(\"spark.jars\", \"ecosystem/spark/spark-tensorflow-connector/target/spark-tensorflow-connector_2.11-1.10.0.jar\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"mys3bucket/yt8pm_100th_shard/v2/video/train*.tfrecord\"\n",
    "df = spark.read.format(\"tfrecords\").option(\"recordType\", \"Example\").load(train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"mys3bucket/yt8pm_100th_shard/v2/video/test*.tfrecord\"\n",
    "df_test = spark.read.format(\"tfrecords\").option(\"recordType\", \"Example\").load(test_path)\n",
    "\n",
    "val_path = \"mys3bucket/yt8pm_100th_shard/v2/video/validate*.tfrecord\"\n",
    "df_val = spark.read.format(\"tfrecords\").option(\"recordType\", \"Example\").load(val_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING\n"
     ]
    }
   ],
   "source": [
    "from elephas.spark_model import SparkModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----+\n",
      "|          mean_audio|              labels|            mean_rgb|  id|\n",
      "+--------------------+--------------------+--------------------+----+\n",
      "|[-1.2556146, 0.17...|             [0, 12]|[0.5198898, 0.301...|eXbF|\n",
      "|[-0.32460678, -0....|[16, 25, 189, 645...|[-0.5026991, -1.6...|BFbF|\n",
      "|[-1.7352352, 1.83...|[2, 44, 64, 113, ...|[0.24258906, 0.97...|GqbF|\n",
      "|[0.7349236, 1.268...|                 [3]|[-0.026906455, -0...|XabF|\n",
      "|[1.2375641, -0.14...|              [1, 5]|[-0.45482802, -1....|3mbF|\n",
      "|[0.50689745, 0.02...|                [14]|[0.45552492, 0.64...|S6bF|\n",
      "|[0.71223485, 1.41...|      [3, 4, 13, 54]|[-0.022711225, 0....|mXbF|\n",
      "|[-0.662256, -0.97...|           [11, 579]|[0.3059462, 0.947...|7sbF|\n",
      "|[0.9852263, 0.145...|[2, 76, 227, 474,...|[0.24360302, 0.40...|H1bF|\n",
      "|[0.10193015, -0.9...| [49, 80, 265, 2063]|[0.60755104, 0.43...|fxbF|\n",
      "|[0.2003511, -1.10...|     [0, 1, 36, 132]|[-0.4298068, -1.0...|w1bF|\n",
      "|[-0.5392725, -0.9...|       [39, 50, 503]|[0.17366871, 0.95...|3obF|\n",
      "|[-0.6388898, 1.07...|           [3, 2195]|[0.089333594, 0.0...|LObF|\n",
      "|[-1.1066483, -0.6...|             [0, 12]|[0.7414522, -1.01...|YwbF|\n",
      "|[1.0145974, 0.175...|      [61, 227, 474]|[-0.25524384, 0.0...|DxbF|\n",
      "|[1.333466, -0.435...|           [5, 3226]|[-0.1797692, -1.2...|NYbF|\n",
      "|[-0.9178203, -0.7...|   [21, 23, 24, 758]|[-0.19473058, 0.6...|I6bF|\n",
      "|[-1.2025927, -0.8...|      [39, 156, 202]|[0.68875366, 0.31...|jmbF|\n",
      "|[0.8315929, -0.57...|       [5, 644, 769]|[-0.0593875, -0.7...|FHbF|\n",
      "|[-1.7979561, -0.9...|[21, 23, 24, 106,...|[-0.9477386, 0.26...|PIbF|\n",
      "+--------------------+--------------------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = df.select('mean_rgb', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            mean_rgb|              labels|\n",
      "+--------------------+--------------------+\n",
      "|[0.5198898, 0.301...|             [0, 12]|\n",
      "|[-0.5026991, -1.6...|[16, 25, 189, 645...|\n",
      "|[0.24258906, 0.97...|[2, 44, 64, 113, ...|\n",
      "|[-0.026906455, -0...|                 [3]|\n",
      "|[-0.45482802, -1....|              [1, 5]|\n",
      "|[0.45552492, 0.64...|                [14]|\n",
      "|[-0.022711225, 0....|      [3, 4, 13, 54]|\n",
      "|[0.3059462, 0.947...|           [11, 579]|\n",
      "|[0.24360302, 0.40...|[2, 76, 227, 474,...|\n",
      "|[0.60755104, 0.43...| [49, 80, 265, 2063]|\n",
      "|[-0.4298068, -1.0...|     [0, 1, 36, 132]|\n",
      "|[0.17366871, 0.95...|       [39, 50, 503]|\n",
      "|[0.089333594, 0.0...|           [3, 2195]|\n",
      "|[0.7414522, -1.01...|             [0, 12]|\n",
      "|[-0.25524384, 0.0...|      [61, 227, 474]|\n",
      "|[-0.1797692, -1.2...|           [5, 3226]|\n",
      "|[-0.19473058, 0.6...|   [21, 23, 24, 758]|\n",
      "|[0.68875366, 0.31...|      [39, 156, 202]|\n",
      "|[-0.0593875, -0.7...|       [5, 644, 769]|\n",
      "|[-0.9477386, 0.26...|[21, 23, 24, 106,...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rdd = train_df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 12]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rdd.take(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rdd = train_rdd.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0.519889771938324,\n",
       "   0.30175963044166565,\n",
       "   -0.51358562707901,\n",
       "   0.41406428813934326,\n",
       "   -0.08573680371046066,\n",
       "   -0.9000590443611145,\n",
       "   1.1310861110687256,\n",
       "   -0.7618379592895508,\n",
       "   -0.5756487250328064,\n",
       "   -0.6951144933700562,\n",
       "   0.836911678314209,\n",
       "   1.244982123374939,\n",
       "   -0.7594509124755859,\n",
       "   0.55865079164505,\n",
       "   -1.3553019762039185,\n",
       "   -0.7772969007492065,\n",
       "   0.3180142641067505,\n",
       "   0.7014186382293701,\n",
       "   0.6312850713729858,\n",
       "   0.0931776612997055,\n",
       "   -1.0130456686019897,\n",
       "   0.28573235869407654,\n",
       "   0.9530810713768005,\n",
       "   -0.10574248433113098,\n",
       "   0.2004808783531189,\n",
       "   0.6593612432479858,\n",
       "   -0.2724944055080414,\n",
       "   0.21014270186424255,\n",
       "   0.6034362316131592,\n",
       "   0.5530810356140137,\n",
       "   0.054757654666900635,\n",
       "   0.20218589901924133,\n",
       "   0.975360095500946,\n",
       "   0.4282728433609009,\n",
       "   -0.6646512746810913,\n",
       "   0.38973918557167053,\n",
       "   0.24117425084114075,\n",
       "   0.104885533452034,\n",
       "   -0.035267919301986694,\n",
       "   0.6658403277397156,\n",
       "   0.47544535994529724,\n",
       "   0.6839136481285095,\n",
       "   -0.47914400696754456,\n",
       "   -0.4416333734989166,\n",
       "   -0.06436709314584732,\n",
       "   0.22742034494876862,\n",
       "   0.600480854511261,\n",
       "   -0.005486732814460993,\n",
       "   -0.022196024656295776,\n",
       "   0.11886677891016006,\n",
       "   0.3614356815814972,\n",
       "   0.25470080971717834,\n",
       "   0.23196709156036377,\n",
       "   0.32551640272140503,\n",
       "   -0.1589394211769104,\n",
       "   0.1512623429298401,\n",
       "   0.8678295612335205,\n",
       "   -0.1640545129776001,\n",
       "   0.3514328598976135,\n",
       "   -0.20770327746868134,\n",
       "   -0.3464927077293396,\n",
       "   -0.7546768188476562,\n",
       "   0.5328480005264282,\n",
       "   0.025090135633945465,\n",
       "   0.9484206438064575,\n",
       "   -0.16712355613708496,\n",
       "   0.2150304615497589,\n",
       "   -0.07005053013563156,\n",
       "   -0.3293287456035614,\n",
       "   0.18786364793777466,\n",
       "   0.19366075098514557,\n",
       "   -0.10199142247438431,\n",
       "   0.4552123248577118,\n",
       "   0.36382272839546204,\n",
       "   -0.34740203619003296,\n",
       "   -0.9254071712493896,\n",
       "   -0.28204256296157837,\n",
       "   -0.37695589661598206,\n",
       "   -0.6530570387840271,\n",
       "   -0.34308263659477234,\n",
       "   -0.37627390027046204,\n",
       "   0.28345897793769836,\n",
       "   -0.06436709314584732,\n",
       "   0.6852777004241943,\n",
       "   -0.06277573853731155,\n",
       "   -0.0068507567048072815,\n",
       "   0.27618420124053955,\n",
       "   0.7249480485916138,\n",
       "   -0.20281551778316498,\n",
       "   0.33381420373916626,\n",
       "   0.10124813765287399,\n",
       "   -0.45902466773986816,\n",
       "   -0.2776094973087311,\n",
       "   -0.9820141792297363,\n",
       "   -0.2540800869464874,\n",
       "   -0.05913833901286125,\n",
       "   0.6320807337760925,\n",
       "   0.1730867326259613,\n",
       "   -0.34126394987106323,\n",
       "   0.004970783833414316,\n",
       "   0.9087502956390381,\n",
       "   0.4499835669994354,\n",
       "   -0.0808490514755249,\n",
       "   0.8257721662521362,\n",
       "   0.3326775133609772,\n",
       "   -0.061980053782463074,\n",
       "   -0.35683655738830566,\n",
       "   -0.1622358113527298,\n",
       "   -0.35683655738830566,\n",
       "   -0.30761802196502686,\n",
       "   0.17229104042053223,\n",
       "   0.34449905157089233,\n",
       "   0.3920125663280487,\n",
       "   0.26379430294036865,\n",
       "   0.34631776809692383,\n",
       "   -0.36195164918899536,\n",
       "   0.05714469775557518,\n",
       "   0.2016175538301468,\n",
       "   0.5508076548576355,\n",
       "   -0.06948218494653702,\n",
       "   0.38973918557167053,\n",
       "   0.12250417470932007,\n",
       "   0.2657266855239868,\n",
       "   -0.007646437268704176,\n",
       "   0.3525695204734802,\n",
       "   0.2941438555717468,\n",
       "   0.5559227466583252,\n",
       "   -0.31386980414390564,\n",
       "   0.21491679549217224,\n",
       "   0.126368910074234,\n",
       "   0.3741665780544281,\n",
       "   -0.2727217376232147,\n",
       "   -0.27363109588623047,\n",
       "   -0.1377970427274704,\n",
       "   0.007471493910998106,\n",
       "   0.2956215441226959,\n",
       "   -0.9071065187454224,\n",
       "   -0.2056572288274765,\n",
       "   -0.6530570387840271,\n",
       "   0.8120182156562805,\n",
       "   -0.6124773621559143,\n",
       "   0.33381420373916626,\n",
       "   0.038730375468730927,\n",
       "   -0.14734521508216858,\n",
       "   0.6446979641914368,\n",
       "   -0.26567429304122925,\n",
       "   0.150125652551651,\n",
       "   0.29732656478881836,\n",
       "   -0.6383938193321228,\n",
       "   0.9037488698959351,\n",
       "   -0.3318294584751129,\n",
       "   -0.3768422305583954,\n",
       "   0.014177944511175156,\n",
       "   -0.395370215177536,\n",
       "   0.19616146385669708,\n",
       "   0.1796795129776001,\n",
       "   -0.19019830226898193,\n",
       "   -0.4884648621082306,\n",
       "   0.3299494683742523,\n",
       "   0.2950531840324402,\n",
       "   0.45600801706314087,\n",
       "   0.17320039868354797,\n",
       "   -0.6986382007598877,\n",
       "   -0.25805848836898804,\n",
       "   0.029182206839323044,\n",
       "   0.37916800379753113,\n",
       "   0.3456357419490814,\n",
       "   0.30130496621131897,\n",
       "   -0.05550093948841095,\n",
       "   -0.34126394987106323,\n",
       "   0.8022427558898926,\n",
       "   -0.5668962001800537,\n",
       "   -0.2556714415550232,\n",
       "   -0.5869019031524658,\n",
       "   -0.08801017701625824,\n",
       "   -0.37195447087287903,\n",
       "   -0.3316020965576172,\n",
       "   0.3857607841491699,\n",
       "   0.09204097092151642,\n",
       "   -0.20111048221588135,\n",
       "   0.1103416308760643,\n",
       "   0.17831549048423767,\n",
       "   -0.43788230419158936,\n",
       "   0.03861670568585396,\n",
       "   -0.028106795623898506,\n",
       "   0.2723194658756256,\n",
       "   0.1836579144001007,\n",
       "   -0.2537390887737274,\n",
       "   0.12227683514356613,\n",
       "   0.16444790363311768,\n",
       "   -0.4128752052783966,\n",
       "   0.28493669629096985,\n",
       "   -0.027083776891231537,\n",
       "   0.3023279905319214,\n",
       "   -0.04026934131979942,\n",
       "   -0.19281268119812012,\n",
       "   -0.07073254138231277,\n",
       "   0.4019017219543457,\n",
       "   -0.43060749769210815,\n",
       "   -0.18837960064411163,\n",
       "   0.11250133067369461,\n",
       "   0.09204097092151642,\n",
       "   0.9446695446968079,\n",
       "   0.13819044828414917,\n",
       "   0.5321660041809082,\n",
       "   -0.08801017701625824,\n",
       "   -0.07698431611061096,\n",
       "   -0.3499027490615845,\n",
       "   -0.1779220849275589,\n",
       "   -0.352062463760376,\n",
       "   -0.12517982721328735,\n",
       "   0.5938881039619446,\n",
       "   0.005311789456754923,\n",
       "   0.2318534255027771,\n",
       "   0.01952037215232849,\n",
       "   -0.49255692958831787,\n",
       "   -0.22702693939208984,\n",
       "   0.5555817484855652,\n",
       "   -0.6398714780807495,\n",
       "   0.12500488758087158,\n",
       "   0.28925609588623047,\n",
       "   0.23958289623260498,\n",
       "   -0.12131509184837341,\n",
       "   -0.5348416566848755,\n",
       "   -0.107106514275074,\n",
       "   -0.6655606031417847,\n",
       "   -0.5638271570205688,\n",
       "   0.16751696169376373,\n",
       "   0.52886962890625,\n",
       "   0.10693156719207764,\n",
       "   -0.6032701730728149,\n",
       "   -0.33501216769218445,\n",
       "   -0.46448075771331787,\n",
       "   0.3923535645008087,\n",
       "   0.7876931428909302,\n",
       "   -0.4589110016822815,\n",
       "   -0.30284392833709717,\n",
       "   0.04839221015572548,\n",
       "   -0.1553020179271698,\n",
       "   -0.16485019028186798,\n",
       "   -0.35285815596580505,\n",
       "   -0.07698431611061096,\n",
       "   -0.13677403330802917,\n",
       "   0.42940953373908997,\n",
       "   -0.4082147777080536,\n",
       "   0.7064200639724731,\n",
       "   -0.46823182702064514,\n",
       "   0.4638511538505554,\n",
       "   -0.1282488852739334,\n",
       "   -0.48516845703125,\n",
       "   -0.4686864912509918,\n",
       "   0.22582897543907166,\n",
       "   -0.5681465864181519,\n",
       "   -0.2738584280014038,\n",
       "   0.4946553409099579,\n",
       "   -0.16541853547096252,\n",
       "   -0.13870640099048615,\n",
       "   -0.4691411852836609,\n",
       "   -0.6199795007705688,\n",
       "   0.0873805582523346,\n",
       "   -0.18974362313747406,\n",
       "   -0.504264771938324,\n",
       "   -0.15064160525798798,\n",
       "   -0.4666404724121094,\n",
       "   0.1730867326259613,\n",
       "   0.09942943602800369,\n",
       "   -0.33569416403770447,\n",
       "   -0.034244902431964874,\n",
       "   -0.21350036561489105,\n",
       "   -0.32955607771873474,\n",
       "   -0.3004568815231323,\n",
       "   -0.32625967264175415,\n",
       "   0.1844535917043686,\n",
       "   0.24708501994609833,\n",
       "   0.048960551619529724,\n",
       "   0.17536009848117828,\n",
       "   0.5688809752464294,\n",
       "   -0.687839686870575,\n",
       "   0.047710198909044266,\n",
       "   -0.01878596469759941,\n",
       "   0.2278750240802765,\n",
       "   -0.2709030508995056,\n",
       "   0.3292674720287323,\n",
       "   0.2044592797756195,\n",
       "   0.06487416476011276,\n",
       "   -0.5298402309417725,\n",
       "   -0.0717555582523346,\n",
       "   0.2777755558490753,\n",
       "   -0.03674561157822609,\n",
       "   0.1658119261264801,\n",
       "   -0.01776294782757759,\n",
       "   -0.41094282269477844,\n",
       "   -0.03663194552063942,\n",
       "   -0.2997748851776123,\n",
       "   -0.09755834192037582,\n",
       "   -0.671130359172821,\n",
       "   -0.07652964442968369,\n",
       "   0.05191593989729881,\n",
       "   -0.41969531774520874,\n",
       "   0.08294748514890671,\n",
       "   -0.2399851679801941,\n",
       "   0.3668917715549469,\n",
       "   -0.10062739998102188,\n",
       "   0.3227883577346802,\n",
       "   -0.05550093948841095,\n",
       "   0.07942375540733337,\n",
       "   -0.42878881096839905,\n",
       "   0.19002336263656616,\n",
       "   -0.022423362359404564,\n",
       "   0.15217168629169464,\n",
       "   -0.033108215779066086,\n",
       "   -0.32921507954597473,\n",
       "   -0.1830371767282486,\n",
       "   -0.16666889190673828,\n",
       "   -0.43526792526245117,\n",
       "   -0.09335260093212128,\n",
       "   0.07999209314584732,\n",
       "   -0.6835202574729919,\n",
       "   0.029068538919091225,\n",
       "   0.02474913001060486,\n",
       "   0.7598443031311035,\n",
       "   -0.2911360561847687,\n",
       "   -0.3238726258277893,\n",
       "   -0.01139750238507986,\n",
       "   -0.200542151927948,\n",
       "   -0.15518835186958313,\n",
       "   0.08453883975744247,\n",
       "   -0.28897637128829956,\n",
       "   0.10931860655546188,\n",
       "   -0.5429121255874634,\n",
       "   -0.14007042348384857,\n",
       "   -0.1293855607509613,\n",
       "   0.4227030873298645,\n",
       "   -0.014011882245540619,\n",
       "   -0.25760382413864136,\n",
       "   -0.2957964837551117,\n",
       "   0.14671559631824493,\n",
       "   -0.3822983205318451,\n",
       "   -0.10744751989841461,\n",
       "   -0.09926337748765945,\n",
       "   0.3008503019809723,\n",
       "   -0.07562029361724854,\n",
       "   0.14035014808177948,\n",
       "   0.7501825094223022,\n",
       "   -0.04277005046606064,\n",
       "   -0.3694537580013275,\n",
       "   -0.13688769936561584,\n",
       "   -0.10790219157934189,\n",
       "   -0.10051372647285461,\n",
       "   -0.2863619923591614,\n",
       "   0.6920977830886841,\n",
       "   0.2016175538301468,\n",
       "   -0.19167599081993103,\n",
       "   0.05100658908486366,\n",
       "   0.3751896023750305,\n",
       "   0.5352350473403931,\n",
       "   -0.25794482231140137,\n",
       "   -0.09903603792190552,\n",
       "   0.10761357843875885,\n",
       "   -0.0648217722773552,\n",
       "   0.021111732348799706,\n",
       "   0.42986422777175903,\n",
       "   0.8396397233009338,\n",
       "   -0.8690274953842163,\n",
       "   0.2625439465045929,\n",
       "   -0.4906245470046997,\n",
       "   -0.4909655749797821,\n",
       "   0.037934694439172745,\n",
       "   -0.03344922140240669,\n",
       "   -0.05766064673662186,\n",
       "   0.04270877689123154,\n",
       "   -0.012193183414638042,\n",
       "   -0.0190133024007082,\n",
       "   0.20434559881687164,\n",
       "   -0.23441541194915771,\n",
       "   0.37916800379753113,\n",
       "   -0.29193174839019775,\n",
       "   0.112160325050354,\n",
       "   0.3975823223590851,\n",
       "   0.13637174665927887,\n",
       "   -0.11756402999162674,\n",
       "   0.012586583383381367,\n",
       "   -0.18144580721855164,\n",
       "   0.13318902254104614,\n",
       "   -0.11347195506095886,\n",
       "   0.13171133399009705,\n",
       "   0.13682642579078674,\n",
       "   0.13216601312160492,\n",
       "   0.6594749093055725,\n",
       "   -0.245782271027565,\n",
       "   0.2569741904735565,\n",
       "   0.0424814410507679,\n",
       "   -0.7721818089485168,\n",
       "   0.43088722229003906,\n",
       "   -0.13882006704807281,\n",
       "   -0.17996811866760254,\n",
       "   -0.15189196169376373,\n",
       "   0.018952028825879097,\n",
       "   0.1256868988275528,\n",
       "   0.2694777548313141,\n",
       "   0.4066758155822754,\n",
       "   0.13603074848651886,\n",
       "   0.13387103378772736,\n",
       "   -0.1625768095254898,\n",
       "   0.3934902548789978,\n",
       "   -0.15336965024471283,\n",
       "   0.25129076838493347,\n",
       "   0.6845957040786743,\n",
       "   0.030887236818671227,\n",
       "   -0.31011873483657837,\n",
       "   0.4377073645591736,\n",
       "   0.19775281846523285,\n",
       "   0.07135327905416489,\n",
       "   -0.3841170370578766,\n",
       "   0.3264257311820984,\n",
       "   -0.24339522421360016,\n",
       "   0.40349307656288147,\n",
       "   -0.20770327746868134,\n",
       "   -0.23930315673351288,\n",
       "   0.13716742396354675,\n",
       "   0.031000906601548195,\n",
       "   -0.09460295736789703,\n",
       "   -0.09039721637964249,\n",
       "   0.14035014808177948,\n",
       "   0.04236777126789093,\n",
       "   -0.4354952573776245,\n",
       "   0.18172554671764374,\n",
       "   0.4062211513519287,\n",
       "   -0.21861545741558075,\n",
       "   0.37393924593925476,\n",
       "   0.24117425084114075,\n",
       "   -0.1680329144001007,\n",
       "   0.3837147355079651,\n",
       "   -0.07164189219474792,\n",
       "   -0.36377033591270447,\n",
       "   0.2113930583000183,\n",
       "   0.8112225532531738,\n",
       "   -0.3632020056247711,\n",
       "   0.07283096760511398,\n",
       "   0.3507508337497711,\n",
       "   0.0822654664516449,\n",
       "   0.4208844006061554,\n",
       "   0.17649678885936737,\n",
       "   -0.3702494502067566,\n",
       "   0.21537145972251892,\n",
       "   0.6320807337760925,\n",
       "   0.4194067120552063,\n",
       "   0.14523790776729584,\n",
       "   -0.13074959814548492,\n",
       "   -0.4556145966053009,\n",
       "   0.40576645731925964,\n",
       "   0.11807109415531158,\n",
       "   0.5601285099983215,\n",
       "   -0.3070496618747711,\n",
       "   -0.27988287806510925,\n",
       "   -0.6851116418838501,\n",
       "   -0.03788229823112488,\n",
       "   -0.22736795246601105,\n",
       "   0.12477754801511765,\n",
       "   -0.16928327083587646,\n",
       "   -0.08141739666461945,\n",
       "   -0.4452707767486572,\n",
       "   -0.404236376285553,\n",
       "   0.19116003811359406,\n",
       "   -0.7131878137588501,\n",
       "   0.08056043833494186,\n",
       "   -0.21816079318523407,\n",
       "   -0.2905677258968353,\n",
       "   0.07692304253578186,\n",
       "   0.11272867023944855,\n",
       "   -0.24646428227424622,\n",
       "   -0.1173366904258728,\n",
       "   0.4953373670578003,\n",
       "   0.2818676233291626,\n",
       "   0.19002336263656616,\n",
       "   0.3164229094982147,\n",
       "   -0.00400904007256031,\n",
       "   0.29948627948760986,\n",
       "   0.37064284086227417,\n",
       "   0.4891992509365082,\n",
       "   -0.14279846847057343,\n",
       "   -0.6749951243400574,\n",
       "   0.2891424298286438,\n",
       "   -0.04561176896095276,\n",
       "   0.06578351557254791,\n",
       "   -0.22259385883808136,\n",
       "   -0.7325114607810974,\n",
       "   0.05782670900225639,\n",
       "   -0.18792492151260376,\n",
       "   0.0012197179021313787,\n",
       "   -0.3023892641067505,\n",
       "   -0.25908151268959045,\n",
       "   0.3310861587524414,\n",
       "   -0.07425627112388611,\n",
       "   0.07271730154752731,\n",
       "   -0.10972089320421219,\n",
       "   -0.30250293016433716,\n",
       "   0.2643626630306244,\n",
       "   -0.13461431860923767,\n",
       "   0.2717511057853699,\n",
       "   0.4522569477558136,\n",
       "   -0.044929757714271545,\n",
       "   -0.1950860470533371,\n",
       "   0.03441096469759941,\n",
       "   0.2949395179748535,\n",
       "   -0.24112185835838318,\n",
       "   0.00042403736733831465,\n",
       "   0.23321744799613953,\n",
       "   0.4291822016239166,\n",
       "   0.025317473337054253,\n",
       "   -0.39480188488960266,\n",
       "   0.03748001903295517,\n",
       "   0.47794607281684875,\n",
       "   0.3107394576072693,\n",
       "   0.22616998851299286,\n",
       "   0.13898612558841705,\n",
       "   -0.02981182560324669,\n",
       "   0.4012197256088257,\n",
       "   -0.6679476499557495,\n",
       "   -0.03583626449108124,\n",
       "   -0.33103376626968384,\n",
       "   0.6370821595191956,\n",
       "   0.09226831048727036,\n",
       "   -0.15246030688285828,\n",
       "   0.7974686622619629,\n",
       "   -0.41310253739356995,\n",
       "   0.28857406973838806,\n",
       "   -0.2059982419013977,\n",
       "   0.0013333866372704506,\n",
       "   0.10147546976804733,\n",
       "   0.3664371073246002,\n",
       "   0.5446695685386658,\n",
       "   0.5895686745643616,\n",
       "   -0.16712355613708496,\n",
       "   -0.027993125841021538,\n",
       "   0.29289349913597107,\n",
       "   -0.0844864472746849,\n",
       "   -0.13404598832130432,\n",
       "   0.4580540359020233,\n",
       "   0.029864219948649406,\n",
       "   0.14364653825759888,\n",
       "   -0.33648985624313354,\n",
       "   0.48453885316848755,\n",
       "   0.2661813497543335,\n",
       "   0.18354424834251404,\n",
       "   0.49113163352012634,\n",
       "   -0.12927189469337463,\n",
       "   -0.1136992946267128,\n",
       "   0.30801141262054443,\n",
       "   0.2351498156785965,\n",
       "   -0.6572628021240234,\n",
       "   -0.547004222869873,\n",
       "   0.230716735124588,\n",
       "   -0.618956446647644,\n",
       "   0.3372242748737335,\n",
       "   -0.148368239402771,\n",
       "   -0.28647565841674805,\n",
       "   0.09113162755966187,\n",
       "   -0.3089820444583893,\n",
       "   0.28016260266304016,\n",
       "   -0.020263658836483955,\n",
       "   0.13523505628108978,\n",
       "   -0.2797692120075226,\n",
       "   0.8731719851493835,\n",
       "   0.05532599985599518,\n",
       "   -0.38423070311546326,\n",
       "   -0.612932026386261,\n",
       "   -0.05527360364794731,\n",
       "   0.3713248670101166,\n",
       "   0.20127655565738678,\n",
       "   0.01031321007758379,\n",
       "   -0.1786040961742401,\n",
       "   -0.07993970066308975,\n",
       "   0.11443369835615158,\n",
       "   0.4799920916557312,\n",
       "   -0.3862767219543457,\n",
       "   -0.5573480725288391,\n",
       "   -0.26749297976493835,\n",
       "   -0.21168167889118195,\n",
       "   -0.5157453417778015,\n",
       "   -0.267265647649765,\n",
       "   -0.10142307728528976,\n",
       "   -0.14200279116630554,\n",
       "   -0.03958733007311821,\n",
       "   0.19047802686691284,\n",
       "   -0.5961090922355652,\n",
       "   0.1223905086517334,\n",
       "   -0.2881806790828705,\n",
       "   -0.005373063962906599,\n",
       "   0.40031036734580994,\n",
       "   0.047823868691921234,\n",
       "   -0.22668594121932983,\n",
       "   0.25060874223709106,\n",
       "   -0.20770327746868134,\n",
       "   -0.3961659073829651,\n",
       "   0.06612452119588852,\n",
       "   0.4019017219543457,\n",
       "   0.2934618294239044,\n",
       "   0.9004524350166321,\n",
       "   0.3438170552253723,\n",
       "   -0.11938272416591644,\n",
       "   -0.3664983808994293,\n",
       "   -0.24225854873657227,\n",
       "   0.14580625295639038,\n",
       "   0.4379346966743469,\n",
       "   -0.3285330533981323,\n",
       "   -0.33092010021209717,\n",
       "   -0.17405734956264496,\n",
       "   -0.0717555582523346,\n",
       "   0.21389377117156982,\n",
       "   0.09692872315645218,\n",
       "   0.5509213209152222,\n",
       "   -0.2552167773246765,\n",
       "   -0.45140886306762695,\n",
       "   -0.42697009444236755,\n",
       "   -0.1761033833026886,\n",
       "   -0.16541853547096252,\n",
       "   -0.6628325581550598,\n",
       "   -0.050954196602106094,\n",
       "   -0.10381011664867401,\n",
       "   -0.1845148652791977,\n",
       "   -0.02185501903295517,\n",
       "   -0.01594424992799759,\n",
       "   0.19775281846523285,\n",
       "   -0.03458590805530548,\n",
       "   -0.12267911434173584,\n",
       "   -0.2490786612033844,\n",
       "   0.1322796791791916,\n",
       "   -0.27522245049476624,\n",
       "   0.21878153085708618,\n",
       "   -0.06902751326560974,\n",
       "   0.765641450881958,\n",
       "   0.27686619758605957,\n",
       "   0.27288779616355896,\n",
       "   -0.7321704626083374,\n",
       "   0.4162239730358124,\n",
       "   0.808494508266449,\n",
       "   0.029182206839323044,\n",
       "   -0.4467484652996063,\n",
       "   0.6681137084960938,\n",
       "   0.13239334523677826,\n",
       "   -0.09767201542854309,\n",
       "   0.4786280691623688,\n",
       "   0.05589434131979942,\n",
       "   0.03179658576846123,\n",
       "   -0.24714629352092743,\n",
       "   0.07101227343082428,\n",
       "   0.10238482058048248,\n",
       "   -0.2451002597808838,\n",
       "   0.15819613635540009,\n",
       "   -0.2436225712299347,\n",
       "   -0.5247251391410828,\n",
       "   -0.049021828919649124,\n",
       "   -0.25226137042045593,\n",
       "   0.24549366533756256,\n",
       "   -0.31853020191192627,\n",
       "   -0.366953045129776,\n",
       "   -0.25442108511924744,\n",
       "   -0.051863543689250946,\n",
       "   0.013836938887834549,\n",
       "   0.12148115783929825,\n",
       "   -0.011511171236634254,\n",
       "   0.06498783081769943,\n",
       "   -0.6656742691993713,\n",
       "   0.2717511057853699,\n",
       "   -0.3497890830039978,\n",
       "   -0.06652680039405823,\n",
       "   -0.20906729996204376,\n",
       "   -0.07107354700565338,\n",
       "   0.2545871436595917,\n",
       "   -0.06618579477071762,\n",
       "   -0.17519403994083405,\n",
       "   -0.4690275192260742,\n",
       "   -0.050954196602106094,\n",
       "   0.2526547908782959,\n",
       "   -0.0688001736998558,\n",
       "   -0.06573112308979034,\n",
       "   0.32869911193847656,\n",
       "   0.23503614962100983,\n",
       "   -0.6449865698814392,\n",
       "   -0.4832361042499542,\n",
       "   0.031228242442011833,\n",
       "   0.2011628895998001,\n",
       "   0.02963688224554062,\n",
       "   -0.5543926954269409,\n",
       "   -0.7053446173667908,\n",
       "   -0.23316505551338196,\n",
       "   0.027249841019511223,\n",
       "   -0.4344722330570221,\n",
       "   -0.41924065351486206,\n",
       "   0.23105773329734802,\n",
       "   -0.01287519559264183,\n",
       "   -0.381161630153656,\n",
       "   -0.29522812366485596,\n",
       "   0.104885533452034,\n",
       "   0.016110312193632126,\n",
       "   -0.009692473337054253,\n",
       "   0.2121887505054474,\n",
       "   0.3365422487258911,\n",
       "   -0.13950207829475403,\n",
       "   -0.33467116951942444,\n",
       "   0.4415720999240875,\n",
       "   0.3227883577346802,\n",
       "   -0.8866461515426636,\n",
       "   -0.1348416656255722,\n",
       "   -0.26635628938674927,\n",
       "   -0.409578800201416,\n",
       "   -0.347515732049942,\n",
       "   -0.3852536976337433,\n",
       "   -0.5173366665840149,\n",
       "   0.6320807337760925,\n",
       "   -0.32955607771873474,\n",
       "   0.4496425688266754,\n",
       "   0.44407281279563904,\n",
       "   0.21775850653648376,\n",
       "   -0.10062739998102188,\n",
       "   0.12989263236522675,\n",
       "   0.3632543981075287,\n",
       "   0.17729246616363525,\n",
       "   0.3971276581287384,\n",
       "   -0.5779221057891846,\n",
       "   0.4446411430835724,\n",
       "   0.1585371345281601,\n",
       "   -0.051863543689250946,\n",
       "   -0.18917527794837952,\n",
       "   -0.04777147248387337,\n",
       "   -0.4795987010002136,\n",
       "   0.5173890590667725,\n",
       "   0.05350729823112488,\n",
       "   0.6556101441383362,\n",
       "   -0.34887975454330444,\n",
       "   -0.5921306610107422,\n",
       "   0.39508160948753357,\n",
       "   0.2803899347782135,\n",
       "   0.30687472224235535,\n",
       "   0.08203813433647156,\n",
       "   0.24765336513519287,\n",
       "   0.17104068398475647,\n",
       "   0.14125950634479523,\n",
       "   0.26663604378700256,\n",
       "   -0.33285245299339294,\n",
       "   0.7218790054321289,\n",
       "   -0.11506331712007523,\n",
       "   -0.06311674416065216,\n",
       "   0.32437971234321594,\n",
       "   0.15615010261535645,\n",
       "   -0.36752140522003174,\n",
       "   -0.23168735206127167,\n",
       "   -0.1104029044508934,\n",
       "   0.42406710982322693,\n",
       "   -0.0564102903008461,\n",
       "   -0.12120142579078674,\n",
       "   0.025431141257286072,\n",
       "   0.2693640887737274,\n",
       "   -0.41276153922080994,\n",
       "   -0.16939693689346313,\n",
       "   -0.15439267456531525,\n",
       "   -0.09562597423791885,\n",
       "   0.21241608262062073,\n",
       "   -0.07198289781808853,\n",
       "   0.44327712059020996,\n",
       "   0.268341064453125,\n",
       "   -0.006737087853252888,\n",
       "   0.22958004474639893,\n",
       "   0.2369685173034668,\n",
       "   0.012472914531826973,\n",
       "   -0.7517214417457581,\n",
       "   -0.3580869138240814,\n",
       "   -0.08869218826293945,\n",
       "   0.04520948603749275,\n",
       "   0.3529105484485626,\n",
       "   0.34108901023864746,\n",
       "   -0.4578879773616791,\n",
       "   0.46817055344581604,\n",
       "   -0.2561261057853699,\n",
       "   0.3924672305583954,\n",
       "   0.2263973206281662,\n",
       "   -0.33830854296684265,\n",
       "   -0.22452622652053833,\n",
       "   0.13500772416591644,\n",
       "   0.47578635811805725,\n",
       "   0.19945785403251648,\n",
       "   -0.19519971311092377,\n",
       "   -0.2515793740749359,\n",
       "   0.21343909204006195,\n",
       "   0.028841201215982437,\n",
       "   0.00042403736733831465,\n",
       "   -0.24464558064937592,\n",
       "   -0.2566944658756256,\n",
       "   -0.3870724141597748,\n",
       "   -0.25805848836898804,\n",
       "   0.14035014808177948,\n",
       "   -0.021627681329846382,\n",
       "   -0.1757623851299286,\n",
       "   -0.21997947990894318,\n",
       "   -0.4683454930782318,\n",
       "   0.1887730062007904,\n",
       "   -0.4070780873298645,\n",
       "   0.3219926655292511,\n",
       "   -0.08130372315645218,\n",
       "   -0.24259954690933228,\n",
       "   -0.32364529371261597,\n",
       "   0.20695997774600983,\n",
       "   0.1081819236278534,\n",
       "   -0.6112269759178162,\n",
       "   -0.10301443934440613,\n",
       "   -0.3971889317035675,\n",
       "   -0.00798744335770607,\n",
       "   0.3277897536754608,\n",
       "   -0.169851616024971,\n",
       "   0.1088639348745346,\n",
       "   -0.45675128698349,\n",
       "   -0.007305431179702282,\n",
       "   -0.22634492814540863,\n",
       "   -0.13109059631824493,\n",
       "   -0.0002579745778348297,\n",
       "   -0.14348047971725464,\n",
       "   0.2848230004310608,\n",
       "   -0.7655890583992004,\n",
       "   0.2519727647304535,\n",
       "   -0.4825540781021118,\n",
       "   -0.47005054354667664,\n",
       "   0.14307819306850433,\n",
       "   -0.134500652551651,\n",
       "   -0.0512952022254467,\n",
       "   -0.13893373310565948,\n",
       "   -0.19372202455997467,\n",
       "   -0.1647365242242813,\n",
       "   0.2303757220506668,\n",
       "   -0.17996811866760254,\n",
       "   0.5854766368865967,\n",
       "   -0.20849895477294922,\n",
       "   -0.46379876136779785,\n",
       "   -0.32955607771873474,\n",
       "   -0.5097208619117737,\n",
       "   0.19468377530574799,\n",
       "   0.6591339111328125,\n",
       "   -0.11665467917919159,\n",
       "   0.3580256402492523,\n",
       "   -0.5061971545219421,\n",
       "   0.04259510710835457,\n",
       "   -0.01287519559264183,\n",
       "   -0.1421164572238922,\n",
       "   0.06419215351343155,\n",
       "   0.3121034801006317,\n",
       "   -0.14711788296699524,\n",
       "   0.3865564465522766,\n",
       "   -0.20952196419239044,\n",
       "   0.17626944184303284,\n",
       "   0.6609525680541992,\n",
       "   -0.07289224863052368,\n",
       "   0.09260931611061096,\n",
       "   0.4081535041332245,\n",
       "   -0.6009967923164368,\n",
       "   -0.011511171236634254,\n",
       "   0.10931860655546188,\n",
       "   -0.058910999447107315,\n",
       "   0.2745928466320038,\n",
       "   0.06123676896095276,\n",
       "   0.1516033560037613,\n",
       "   0.43929871916770935,\n",
       "   -0.11801870167255402,\n",
       "   -0.3128467798233032,\n",
       "   0.1220494955778122,\n",
       "   -0.11961006373167038,\n",
       "   -0.19122131168842316,\n",
       "   0.05202960595488548,\n",
       "   -0.10960721969604492,\n",
       "   -0.37070411443710327,\n",
       "   -0.04390673711895943,\n",
       "   0.216508150100708,\n",
       "   0.2734561562538147,\n",
       "   -0.09062455594539642,\n",
       "   -0.17633071541786194,\n",
       "   -0.0015083297621458769,\n",
       "   0.14410121738910675,\n",
       "   0.07805973291397095,\n",
       "   0.2567468583583832,\n",
       "   0.16478891670703888,\n",
       "   -0.381161630153656,\n",
       "   0.11375168710947037,\n",
       "   0.09420067816972733,\n",
       "   -0.14348047971725464,\n",
       "   -0.030152831226587296,\n",
       "   0.08397050201892853,\n",
       "   0.17501908540725708,\n",
       "   0.13887245953083038,\n",
       "   -0.19860978424549103,\n",
       "   -0.2665836215019226,\n",
       "   -0.15405166149139404,\n",
       "   -0.5894026160240173,\n",
       "   -0.09994538873434067,\n",
       "   -0.14166177809238434,\n",
       "   -0.3022755980491638,\n",
       "   -0.1596214324235916,\n",
       "   -0.2424858808517456,\n",
       "   -0.19645006954669952,\n",
       "   -0.1399567574262619,\n",
       "   -0.4559556245803833,\n",
       "   0.16331122815608978,\n",
       "   0.03838936984539032,\n",
       "   -0.3250093162059784,\n",
       "   -0.2735174298286438,\n",
       "   -0.3499027490615845,\n",
       "   -0.4239010512828827,\n",
       "   -0.24009883403778076,\n",
       "   -0.019467977806925774,\n",
       "   0.02440812438726425,\n",
       "   0.046687182039022446,\n",
       "   -0.11688201874494553,\n",
       "   0.13784943521022797,\n",
       "   0.22923904657363892,\n",
       "   -0.2034975290298462,\n",
       "   -0.040724016726017,\n",
       "   -0.2300959974527359,\n",
       "   -0.26021820306777954,\n",
       "   0.30175963044166565,\n",
       "   0.23139874637126923,\n",
       "   -0.37616023421287537,\n",
       "   0.4377073645591736,\n",
       "   -0.3734321594238281,\n",
       "   0.4474828541278839,\n",
       "   -0.3119374215602875,\n",
       "   0.22571530938148499,\n",
       "   -0.23839381337165833,\n",
       "   -0.3486523926258087,\n",
       "   -0.15768906474113464,\n",
       "   -0.10449213534593582,\n",
       "   -0.0666404664516449,\n",
       "   -0.06027502566576004,\n",
       "   -0.016057917848229408,\n",
       "   -0.07709798961877823,\n",
       "   0.18206654489040375,\n",
       "   -0.23464274406433105,\n",
       "   0.47760504484176636,\n",
       "   0.007130488287657499,\n",
       "   -0.01889963448047638,\n",
       "   -0.39957594871520996,\n",
       "   0.2515181005001068,\n",
       "   -0.10653816908597946,\n",
       "   0.06407848745584488,\n",
       "   0.08931292593479156,\n",
       "   -0.6117953658103943,\n",
       "   -0.13393230736255646,\n",
       "   0.005766464397311211,\n",
       "   0.14341920614242554,\n",
       "   -0.6191837787628174,\n",
       "   -0.44413408637046814,\n",
       "   0.4913589656352997,\n",
       "   0.04805120453238487,\n",
       "   0.024862797930836678,\n",
       "   0.3920125663280487,\n",
       "   -0.16666889190673828,\n",
       "   -0.025151411071419716,\n",
       "   0.4897676110267639,\n",
       "   -0.10040006041526794,\n",
       "   0.47214895486831665,\n",
       "   -0.3578595519065857,\n",
       "   -0.2107723206281662,\n",
       "   -0.31205108761787415,\n",
       "   -0.722963273525238,\n",
       "   0.25981590151786804,\n",
       "   0.3784859776496887,\n",
       "   -0.7000021934509277,\n",
       "   0.059872742742300034,\n",
       "   -0.033221885561943054,\n",
       "   -0.2962511479854584,\n",
       "   0.3857607841491699,\n",
       "   -0.11381296068429947,\n",
       "   -0.03367656096816063,\n",
       "   -0.0458391048014164,\n",
       "   0.4111088812351227,\n",
       "   -0.089260533452034,\n",
       "   -0.267606645822525,\n",
       "   0.06794321537017822,\n",
       "   -0.08937419950962067,\n",
       "   -0.54166179895401,\n",
       "   -0.54200279712677,\n",
       "   -0.3504711091518402,\n",
       "   0.2354908138513565,\n",
       "   0.2726604640483856,\n",
       "   -0.0295844879001379,\n",
       "   -0.035949934273958206,\n",
       "   -0.2410081923007965,\n",
       "   0.2789122462272644,\n",
       "   0.2990315854549408,\n",
       "   -0.23214203119277954,\n",
       "   -0.11335828900337219,\n",
       "   0.19763915240764618,\n",
       "   -0.357063889503479,\n",
       "   -0.3910508155822754,\n",
       "   -0.40469104051589966,\n",
       "   -0.031062180176377296,\n",
       "   -0.11813236773014069,\n",
       "   -0.40184932947158813,\n",
       "   -0.3370582163333893,\n",
       "   0.28243598341941833,\n",
       "   0.1606968492269516,\n",
       "   -0.14916391670703888,\n",
       "   0.03543398156762123,\n",
       "   ...],\n",
       "  [0, 12])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(labels):\n",
    "    allowed=np.arange(20)\n",
    "    one_hot=np.zeros(20)\n",
    "    for l in labels:\n",
    "        if l in allowed:\n",
    "            one_hot[l]=1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_rdd = train_rdd.map(lambda x: np.array([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rdd = train_rdd.map(lambda x: (np.array(x[0]), convert_labels(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 0.51988977,  0.30175963, -0.51358563, ...,  0.44089007,\n",
       "          0.39803699, -0.48050806]),\n",
       "  array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0.])),\n",
       " (array([-0.50269908, -1.64767921,  0.25519568, ..., -0.00722509,\n",
       "          0.06011974,  0.2744202 ]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0.]))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-d72ac36c7812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1133\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_rdd.mapPartitions(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_model = SparkModel(model, frequency='epoch', mode='synchronous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Fit model\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 10 in stage 6.0 failed 1 times, most recent failure: Lost task 10.0 in stage 6.0 (TID 56, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/worker.py\", line 45, in train\n    self.model.fit(x_train, y_train, **self.train_config)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\", line 1039, in fit\n    validation_steps=validation_steps)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 199, in fit_loop\n    outs = f(ins_batch)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\n    return self._call(inputs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\n    fetched = self._callable_fn(*array_vals)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1439, in __call__\n    run_metadata_ptr)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n    c_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[32,500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node batch_normalization_1_10/batchnorm/mul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics_21/acc/Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2050)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2069)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2094)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:935)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:467)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/worker.py\", line 45, in train\n    self.model.fit(x_train, y_train, **self.train_config)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\", line 1039, in fit\n    validation_steps=validation_steps)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 199, in fit_loop\n    outs = f(ins_batch)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\n    return self._call(inputs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\n    fetched = self._callable_fn(*array_vals)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1439, in __call__\n    run_metadata_ptr)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n    c_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[32,500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node batch_normalization_1_10/batchnorm/mul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics_21/acc/Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5bba74b3376d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_rdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/spark_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, rdd, epochs, batch_size, verbose, validation_split)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'asynchronous'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'synchronous'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hogwild'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/spark_model.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, rdd, epochs, batch_size, verbose, validation_split)\u001b[0m\n\u001b[1;32m    186\u001b[0m             worker = SparkWorker(yaml, parameters, train_config,\n\u001b[1;32m    187\u001b[0m                                  optimizer, loss, metrics, custom)\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0mnew_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_master_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# simply accumulate gradients one by one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 10 in stage 6.0 failed 1 times, most recent failure: Lost task 10.0 in stage 6.0 (TID 56, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/worker.py\", line 45, in train\n    self.model.fit(x_train, y_train, **self.train_config)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\", line 1039, in fit\n    validation_steps=validation_steps)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 199, in fit_loop\n    outs = f(ins_batch)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\n    return self._call(inputs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\n    fetched = self._callable_fn(*array_vals)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1439, in __call__\n    run_metadata_ptr)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n    c_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[32,500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node batch_normalization_1_10/batchnorm/mul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics_21/acc/Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2050)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2069)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2094)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:935)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:467)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/elephas/worker.py\", line 45, in train\n    self.model.fit(x_train, y_train, **self.train_config)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\", line 1039, in fit\n    validation_steps=validation_steps)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 199, in fit_loop\n    outs = f(ins_batch)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\n    return self._call(inputs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\n    fetched = self._callable_fn(*array_vals)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1439, in __call__\n    run_metadata_ptr)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n    c_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[32,500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node batch_normalization_1_10/batchnorm/mul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics_21/acc/Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "spark_model.fit(train_rdd, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_indices = np.random.permutation(np.arange(len(labels)))\n",
    "vid_sample = np.array(video_rgb)[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_rgb, train_video_audio, train_labels, val_video_rgb, val_video_audio, val_labels =\\\n",
    "get_train_data(video_rgb, video_audio, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting callbacks\n",
    "STAMP = 'lstm_%d_%d_%.2f_%.2f' % (number_lstm_units, number_dense_units, rate_drop_lstm, rate_drop_dense)\n",
    "checkpoint_dir = 'checkpoints/' + str(int(time.time())) + '/'\n",
    "bst_model_path = checkpoint_dir + STAMP + '.h5'\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=False)\n",
    "tensorboard = TensorBoard(log_dir=checkpoint_dir + \"logs/{}\".format(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to hot-encode labels into 20 TOP frequent categories (last one will be dummy)\n",
    "all_cats = train_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4, 13], [106], [3, 8, 89], ..., [5, 2411], [315, 505],\n",
       "       [3, 6, 13]], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "for i in list(all_cats):\n",
    "    for j in list(i):\n",
    "        all_labels.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.unique(all_labels,return_counts=True)\n",
    "labels,counts = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6797, 4675, 3571, 3141, 2433, 2062, 1688, 1643, 1518, 1322, 1237,\n",
       "        1189, 1175, 1081,  950,  888,  856,  831,  732,  713]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[:20],labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 13]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]),)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,2,3])\n",
    "np.where(x==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to create a sequence-like matrix where for each input I will have a sequence of 20 of 0s and 1s, \n",
    "# indicating which feature is there and which is not\n",
    "\n",
    "def create_y(raw_labels=train_labels,label_size=20,labels_vocab=labels):\n",
    "    \n",
    "    labels = labels_vocab[:label_size-1] #last columns will be 1 if none of those labels found in a video\n",
    "    output = []\n",
    "    for set_of_labels in raw_labels:\n",
    "        \n",
    "        # preallocate numpy arr for each set of labels\n",
    "        sequence = np.zeros(label_size)\n",
    "        # loop through all the labels in one video and flip them to 1s\n",
    "        for this_label in set_of_labels:\n",
    "            designation = np.where(labels==this_label)\n",
    "            for des in designation:\n",
    "                sequence[des]=1\n",
    "        # done with one training points\n",
    "        if sequence.sum()==0:\n",
    "            sequence[-1]=1\n",
    "        output.append(sequence)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = create_y(train_labels,20,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_seq = np.stack(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33115, 20)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels_seq = np.stack(create_y(val_labels,20,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8278, 20)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33115 samples, validate on 8278 samples\n",
      "Epoch 1/5\n",
      "33115/33115 [==============================] - 9s 269us/step - loss: 0.1434 - acc: 0.9417 - val_loss: 0.0791 - val_acc: 0.9719\n",
      "Epoch 2/5\n",
      "33115/33115 [==============================] - 8s 238us/step - loss: 0.0650 - acc: 0.9754 - val_loss: 0.0699 - val_acc: 0.9731\n",
      "Epoch 3/5\n",
      "33115/33115 [==============================] - 8s 239us/step - loss: 0.0535 - acc: 0.9796 - val_loss: 0.0695 - val_acc: 0.9745\n",
      "Epoch 4/5\n",
      "33115/33115 [==============================] - 8s 244us/step - loss: 0.0453 - acc: 0.9826 - val_loss: 0.0743 - val_acc: 0.9738\n",
      "Epoch 5/5\n",
      "33115/33115 [==============================] - 8s 239us/step - loss: 0.0386 - acc: 0.9853 - val_loss: 0.0783 - val_acc: 0.9734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3e5be2d68>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([train_video_rgb, train_video_audio], train_label_seq,\n",
    "              validation_data=([val_video_rgb, val_video_audio], val_labels_seq),\n",
    "              epochs=5, batch_size=64, shuffle=True, callbacks=[early_stopping, tensorboard]) # got rid of checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
